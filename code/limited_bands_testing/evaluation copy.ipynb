{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the tiles using pretrained tile2vec\n",
    "In this notebook we are going to measure the performance of classifier on EuroSATallbands dataset.\n",
    "\n",
    "We will use model weights that are in the `/storage/tile2vec/models/`. Firstly we need to load the weights and create the embeddings of the tiles using our pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model\n",
    "\n",
    "Firstly we need to load the pretrained model. We use a simple function that loads the checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.tilenet import make_tilenet\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "def load_model(model_filepath, bands = 13, z_dim = 512):\n",
    "    \n",
    "    model_dir = Path('/storage/tile2vec/models/limited_bands_models')\n",
    "    model_fn = model_dir / model_filepath # specify which model weights are to be loaded\n",
    "    \n",
    "    bands = bands # number of bands in the input data - should matche the model\n",
    "    z_dim = z_dim # output dimension of the last layer of the encoder - should match the model\n",
    "\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "    tilenet = make_tilenet(in_channels=bands, z_dim=z_dim) \n",
    "    if cuda: \n",
    "        tilenet.cuda()\n",
    "        \n",
    "    print(\"Model filepath: \", model_fn)\n",
    "\n",
    "    checkpoint = torch.load(model_fn)\n",
    "    tilenet.load_state_dict(checkpoint)\n",
    "    tilenet.eval()\n",
    "    print(\"Model succesfully loaded\")\n",
    "    return tilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filepath:  /storage/tile2vec/models/limited_bands_models/Tile2Vec_moisture.ckpt\n",
      "Model succesfully loaded\n"
     ]
    }
   ],
   "source": [
    "# tilenet = load_model(Path('Tile2Vec_color_infrated.ckpt'), bands=3)\n",
    "# tilenet = load_model(Path('Tile2Vec_agriculture.ckpt'), bands=3)\n",
    "# tilenet = load_model(Path('Tile2Vec_vegetation.ckpt'), bands=2)\n",
    "tilenet = load_model(Path('Tile2Vec_moisture.ckpt'), bands=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the bare files and organize them into a dataframe\n",
    "\n",
    "We need to load the files to perform evaluation. To evaluate performance of our trained unsupervised model, we need to perform a simple inference (forward pass) on the tiles and then create a classfier. Here we will use random forests and logistic regression. \n",
    "\n",
    "The classifier models will be trained using the embeddings from joined test and validation dataset. Because our dataset is quite well-balanced, our metric is set to be the accuracy measured using the 5-fold crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from src.data_utils import clip_and_scale_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 123/5519 [00:00<00:04, 1224.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:03<00:00, 1663.26it/s]\n",
      "100%|██████████| 2759/2759 [00:01<00:00, 2141.36it/s]\n",
      "100%|██████████| 19317/19317 [00:14<00:00, 1287.95it/s]\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"/storage/EuroSATallBands/validation.csv\")\n",
    "n_tiles = len(val_df)\n",
    "tiles_path = Path(\"/storage/tile2vec/npy/val\")\n",
    "\n",
    "X_bare_val = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "X_norm_val = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "\n",
    "for index in tqdm(range(n_tiles)):\n",
    "    tile = np.load(tiles_path / f\"{index}.npy\")\n",
    "    X_norm_val[index] = clip_and_scale_image(tile, img_type=\"landsat\").flatten()\n",
    "    X_bare_val[index] = tile.flatten()\n",
    "    \n",
    "y_val = val_df[\"Label\"]\n",
    "\n",
    "test_df = pd.read_csv(\"/storage/EuroSATallBands/test.csv\")\n",
    "n_tiles = len(test_df)\n",
    "tiles_path = Path(\"/storage/tile2vec/npy/test\")\n",
    "\n",
    "X_bare_test = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "X_norm_test = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "\n",
    "for index in tqdm(range(n_tiles)):\n",
    "    tile = np.load(tiles_path / f\"{index}.npy\")\n",
    "    X_norm_test[index] = clip_and_scale_image(tile, img_type=\"landsat\").flatten()\n",
    "    X_bare_test[index] = tile.flatten()\n",
    "    \n",
    "y_test = test_df[\"Label\"]\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"/storage/EuroSATallBands/train.csv\")\n",
    "n_tiles = len(train_df)\n",
    "tiles_path = Path(\"/storage/tile2vec/npy/train\")\n",
    "\n",
    "X_bare_train = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "X_norm_train = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "\n",
    "for index in tqdm(range(n_tiles)):\n",
    "    tile = np.load(tiles_path / f\"{index}.npy\")\n",
    "    X_norm_train[index] =  clip_and_scale_image(tile, img_type=\"sentinel\").flatten()\n",
    "\n",
    "    X_bare_train[index] = tile.flatten()\n",
    "    \n",
    "y_train = train_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"Label\"]\n",
    "y_validation = val_df[\"Label\"]\n",
    "y_test = test_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_valtest = np.concatenate((X_norm_val, X_norm_test), axis=0)\n",
    "y_valtest = np.concatenate((y_validation, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to compare our model with different methods of dimentionality reduction. Therefore we create variables to evaluate performance of different methods. In the code above we create 6 matrices, two for each part of our data. Each matrix contains observations from sets. For instance, X_*_train contains images as rows, which are flattened to a row-vector. Each collum contains information about pixel on a specific position in the image.\n",
    "\n",
    "## Embeddings\n",
    "Below there is a function that creates embeddings from the provided path and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_embeddings_tile2vec(tilenet, \n",
    "                               df_filepath: str | Path, \n",
    "                               tiles_path: str | Path, \n",
    "                               img_type: str = \"sentinel\", \n",
    "                               bands: int = 13, \n",
    "                               z_dim: int = 512):\n",
    "    \"\"\"\n",
    "    function creates matrix X and y containing embeddings and labels, loads the tiles from directory `tiles_path`\n",
    "    \"\"\"\n",
    "    df_filepath = Path(df_filepath)\n",
    "    tiles_path = Path(tiles_path)\n",
    "    df = pd.read_csv(df_filepath)\n",
    "    n_tiles = len(df)    \n",
    "    \n",
    "    X = np.zeros((n_tiles, z_dim))\n",
    "    \n",
    "    t0 = time()\n",
    "    # this solution to iterate over examples is very suboptimal, one should use torch dataset\n",
    "    for index in tqdm(range(n_tiles)):\n",
    "        # read the tile from provided filepath\n",
    "        \n",
    "        tile = np.load(tiles_path / f\"{index}.npy\")  \n",
    "        tile = clip_and_scale_image(tile, img_type=img_type)[:, :bands,:, :]\n",
    "        tile = torch.from_numpy(tile).float()\n",
    "        tile = (tile)\n",
    "        if cuda: \n",
    "            tile = tile.cuda()\n",
    "        z = tilenet.encode(tile)\n",
    "        if cuda: \n",
    "            z = z.cpu()\n",
    "        z = z.data.numpy()\n",
    "        \n",
    "        X[index,:] = z\n",
    "\n",
    "    t1 = time()\n",
    "    print('Embedded {} tiles: {:0.3f}s'.format(n_tiles, t1-t0))\n",
    "    \n",
    "    y = df['Label'].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compare_results(X, y, model, folds=5, model_name=\"\"):\n",
    "    if model_name == \"\":\n",
    "        model_name = model.__class__.__name__\n",
    "    \n",
    "    # Prepare for cross-validation\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=1)\n",
    "    \n",
    "    # Initialize dictionary to store accuracies for each label\n",
    "    unique_labels = np.unique(y)\n",
    "    label_accuracies = {label: [] for label in unique_labels}\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        for label in unique_labels:\n",
    "            # Select samples with the current label\n",
    "            mask = (y_test == label)\n",
    "            y_test_label = y_test[mask]\n",
    "            y_pred_label = y_pred[mask]\n",
    "            \n",
    "            if len(y_test_label) > 0:  # Avoid division by zero if no samples have the current label\n",
    "                accuracy = accuracy_score(y_test_label, y_pred_label)\n",
    "                label_accuracies[label].append(accuracy)\n",
    "    \n",
    "    # Print averaged accuracies for each label\n",
    "    for label, accuracies in label_accuracies.items():\n",
    "        if accuracies:  # Avoid printing if there were no accuracies recorded\n",
    "            mean_accuracy = np.mean(accuracies)\n",
    "            std_accuracy = np.std(accuracies)\n",
    "            print(f\"Averaged accuracy for model {model_name} on label {label}: {mean_accuracy*100:.2f}±{std_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Finally we perform tests, each section contains code and results of evaluation - the results and model or method type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default model scaling\n",
    "Here we are going to check the performance of model with no band-specfic scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filepath:  /storage/tile2vec/models/limited_bands_models/Tile2Vec_moisture.ckpt\n",
      "Model succesfully loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:36<00:00, 153.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 5519 tiles: 36.075s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [00:17<00:00, 161.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 2759 tiles: 17.117s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# no_clipping = load_model(\"Tile2Vec_color_infrated.ckpt\", bands=3)\n",
    "# no_clipping = load_model(\"Tile2Vec_agriculture.ckpt\", bands=3)\n",
    "# no_clipping = load_model(\"Tile2Vec_vegetation.ckpt\", bands=2)\n",
    "no_clipping = load_model(\"Tile2Vec_moisture.ckpt\", bands=2)\n",
    "\n",
    "X_validation, y_validation = create_embeddings_tile2vec(no_clipping, '/storage/EuroSATallBands/validation.csv', '/storage/tile2vec/tif/val', \"landsat\", bands=2)\n",
    "X_test, y_test = create_embeddings_tile2vec(no_clipping, '/storage/EuroSATallBands/test.csv', '/storage/tile2vec/tif/test', \"landsat\", bands=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_validation, X_test), axis=0)  \n",
    "y = np.concatenate((y_validation, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model RandomForestClassifier on label 0: 44.10±4.07%\n",
      "Averaged accuracy for model RandomForestClassifier on label 1: 77.21±2.27%\n",
      "Averaged accuracy for model RandomForestClassifier on label 2: 34.15±6.07%\n",
      "Averaged accuracy for model RandomForestClassifier on label 3: 12.10±2.23%\n",
      "Averaged accuracy for model RandomForestClassifier on label 4: 83.29±1.71%\n",
      "Averaged accuracy for model RandomForestClassifier on label 5: 58.30±5.05%\n",
      "Averaged accuracy for model RandomForestClassifier on label 6: 28.43±5.05%\n",
      "Averaged accuracy for model RandomForestClassifier on label 7: 50.89±1.24%\n",
      "Averaged accuracy for model RandomForestClassifier on label 8: 25.25±4.24%\n",
      "Averaged accuracy for model RandomForestClassifier on label 9: 55.07±3.89%\n"
     ]
    }
   ],
   "source": [
    "compare_results(X, y, rf, folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model LogisticRegression on label 0: 0.00±0.00%\n",
      "Averaged accuracy for model LogisticRegression on label 1: 0.00±0.00%\n",
      "Averaged accuracy for model LogisticRegression on label 2: 0.00±0.00%\n",
      "Averaged accuracy for model LogisticRegression on label 3: 0.00±0.00%\n",
      "Averaged accuracy for model LogisticRegression on label 4: 0.00±0.00%\n",
      "Averaged accuracy for model LogisticRegression on label 5: 0.00±0.00%\n",
      "Averaged accuracy for model LogisticRegression on label 6: 0.00±0.00%\n",
      "Averaged accuracy for model LogisticRegression on label 7: 0.00±0.00%\n",
      "Averaged accuracy for model LogisticRegression on label 8: 0.00±0.00%\n",
      "Averaged accuracy for model LogisticRegression on label 9: 100.00±0.00%\n"
     ]
    }
   ],
   "source": [
    "compare_results(X, y, lr, folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Heatmap of predictions')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf.fit(X_validation, y_validation)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred))\n",
    "plt.title(\"Heatmap of predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom outlier clipping\n",
    "Here we evaluate performance of model with band normalization based on IQR on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filepath:  /storage/tile2vec/models/limited_bands_models/Tile2Vec_moisture.ckpt\n",
      "Model succesfully loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5519 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 2, 3, 3], expected input[1, 3, 64, 64] to have 2 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# custom_clipping = load_model(\"Tile2Vec_color_infrated.ckpt\", bands=3)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# custom_clipping = load_model(\"Tile2Vec_agriculture.ckpt\", bands=3)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# custom_clipping = load_model(\"Tile2Vec_vegetation.ckpt\", bands=2)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m custom_clipping \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTile2Vec_moisture.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, bands\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m X_validation, y_validation \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_embeddings_tile2vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_clipping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/storage/EuroSATallBands/validation.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/storage/tile2vec/tif/val\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m create_embeddings_tile2vec(custom_clipping, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/storage/EuroSATallBands/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/storage/tile2vec/tif/test\u001b[39m\u001b[38;5;124m'\u001b[39m, bands\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      9\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((X_validation, X_test), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mcreate_embeddings_tile2vec\u001b[0;34m(tilenet, df_filepath, tiles_path, img_type, bands, z_dim)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cuda: \n\u001b[1;32m     27\u001b[0m     tile \u001b[38;5;241m=\u001b[39m tile\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 28\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mtilenet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cuda: \n\u001b[1;32m     30\u001b[0m     z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m/volume/home/maciej/WB_projekt/code/limited_bands_testing/../src/tilenet.py:64\u001b[0m, in \u001b[0;36mTileNet.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 64\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     65\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m     66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n",
      "File \u001b[0;32m~/.conda/envs/tile2vec/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tile2vec/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tile2vec/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tile2vec/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 2, 3, 3], expected input[1, 3, 64, 64] to have 2 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "# custom_clipping = load_model(\"Tile2Vec_color_infrated.ckpt\", bands=3)\n",
    "# custom_clipping = load_model(\"Tile2Vec_agriculture.ckpt\", bands=3)\n",
    "# custom_clipping = load_model(\"Tile2Vec_vegetation.ckpt\", bands=2)\n",
    "custom_clipping = load_model(\"Tile2Vec_moisture.ckpt\", bands=2)\n",
    "\n",
    "X_validation, y_validation = create_embeddings_tile2vec(custom_clipping, '/storage/EuroSATallBands/validation.csv', '/storage/tile2vec/tif/val', bands=3)\n",
    "X_test, y_test = create_embeddings_tile2vec(custom_clipping, '/storage/EuroSATallBands/test.csv', '/storage/tile2vec/tif/test', bands=3)\n",
    "\n",
    "X = np.concatenate((X_validation, X_test), axis=0)\n",
    "y = np.concatenate((y_validation, y_test), axis=0)\n",
    "\n",
    "compare_results(X, y, rf, folds = 5)\n",
    "compare_results(X, y, lr, folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Heatmap of predictions')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAGxCAYAAAAH0U5DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAz0lEQVR4nO3de1zUZfr/8ffIYUREFIiTBzTPClpKq5LlmcIkD5WaHbDMdD1sZKah9VNblaxN7ZHp1moeM2q/ZdnJxDwUSxZalpqZbR4LokxBDUeF+/dH6+zOQWRscNBez318Ho/mns/cc83QxsV13Z/7YzHGGAEAAPyPar4OAAAAVD0kCAAAwAUJAgAAcEGCAAAAXJAgAAAAFyQIAADABQkCAABwQYIAAABckCAAAAAXJAg4pyVLlshisWjLli1un+/Tp48aNmxYqTHk5uZq6tSpOnr0aKW+T1XxwQcfKDExUcHBwbJYLHrjjTd8HVK5GjZsqKFDh9ofb9y4URaLRRs3bvRonvJ+zl27dlXXrl1/V5wAPEeCgCotNzdX06ZN+0MkCMYYDRw4UAEBAVq9erU+/vhjdenSxddheaRdu3b6+OOP1a5dO49eV97Pef78+Zo/f76XIgRQUf6+DgDAb3744Qf98ssv6t+/v3r06FGp7/Xrr7+qRo0aXp+3Vq1a6tixo1fnbNWqlVfnA1AxVBDgVcYYzZ8/X1dddZWCgoJUp04d3Xrrrfruu+8czsvOzlbfvn1Vr149Va9eXU2aNNGIESP0888/28+ZOnWqHn74YUlSo0aNZLFYHMrXDRs2VJ8+ffT222/r6quvVlBQkFq2bKm3335b0m8tkpYtWyo4OFh/+tOfXFolW7Zs0eDBg9WwYUMFBQWpYcOGuv3227V//36H8862WrKzs3XPPfcoLCxMwcHBSk1Ndflc55KTk6MePXooJCRENWrUUFJSkt555x2Hz1qvXj1J0sSJE2WxWMpt35wt5a9YsULjxo1TdHS0goKC1KVLF33++ecO5w4dOlQ1a9bU9u3blZycrJCQEHsCcurUKU2fPl0tWrSQ1WrVFVdcoXvuuUc//fSTwxynT5/WhAkTFB0drRo1aqhz58769NNPzxmXc4vhk08+UWpqqsLDw1W9enU1btxY6enp9s9e3s/ZXYvhl19+0ahRo1S3bl0FBgbqyiuv1OTJk2Wz2RzOs1gsGjNmjJYvX66WLVuqRo0aatu2rf3fkbN++ukn3X///apfv779e7j22mu1bt26c/4MgMsdFQScV2lpqc6cOeMy7u5GoCNGjNCSJUv0l7/8RbNmzdIvv/yixx9/XElJSfriiy8UFRUlSfr3v/+tTp066b777lNoaKj27dun2bNnq3Pnztq+fbsCAgJ033336ZdfftGzzz6r119/XTExMZIc/6L84osvlJGRocmTJys0NFTTpk3TgAEDlJGRoQ8++EAzZ86UxWLRxIkT1adPH+3du1dBQUGSpH379ql58+YaPHiwwsLClJ+frwULFuiaa67RV199pYiICIfPNmzYMPXq1UsrV67UwYMH9eijj6pr16768ssvVbt27XN+f5s2bVKvXr3Upk0bLVq0SFarVfPnz1dqaqpefvllDRo0SPfdd5/atm2rAQMGaOzYsRoyZIisVut5fzaTJk1Su3bttHDhQhUVFWnq1Knq2rWrPv/8c1155ZX2806dOqWbb75ZI0aM0COPPKIzZ86orKxMffv21UcffaQJEyYoKSlJ+/fv15QpU9S1a1dt2bLF/l0NHz5cy5Yt0/jx49WrVy/t2LFDAwYM0LFjx84b4/vvv6/U1FS1bNlSs2fPVoMGDbRv3z6tXbtWkir0c/5fJ0+eVLdu3fTvf/9b06ZNU5s2bfTRRx8pMzNT27Ztc0i8JOmdd95RXl6eHn/8cdWsWVNPPvmk+vfvr927d9u/o7vuukufffaZZsyYoWbNmuno0aP67LPPdPjw4fN+PuCyZYBzWLx4sZFU7hEXF2c//+OPPzaSzNNPP+0wz8GDB01QUJCZMGGC2/cpKyszp0+fNvv37zeSzJtvvml/7qmnnjKSzN69e11eFxcXZ4KCgsyhQ4fsY9u2bTOSTExMjDlx4oR9/I033jCSzOrVq8/5ec+cOWOOHz9ugoODzTPPPOPyPfTv39/h/H/9619Gkpk+ffo55zTGmI4dO5rIyEhz7Ngxh/eKj4839erVM2VlZcYYY/bu3Wskmaeeeqrc+YwxZsOGDUaSadeunf31xhizb98+ExAQYO677z77WFpampFkXnzxRYc5Xn75ZSPJvPbaaw7jeXl5RpKZP3++McaYXbt2GUnmwQcfdDjvpZdeMpJMWlqaS1wbNmywjzVu3Ng0btzYlJSUnPPzlPdz7tKli+nSpYv98d///ncjybz66qsO582aNctIMmvXrrWPSTJRUVGmuLjYPlZQUGCqVatmMjMz7WM1a9Y06enp54wP+COixYDzWrZsmfLy8lyOzp07O5z39ttvy2Kx6M4779SZM2fsR3R0tNq2betQdi4sLNTIkSNVv359+fv7KyAgQHFxcZKkXbt2VTi2q666SnXr1rU/btmypaTfytL/22M/O/6/7YPjx49r4sSJatKkifz9/eXv76+aNWvqxIkTbmO44447HB4nJSUpLi5OGzZsOGd8J06c0CeffKJbb71VNWvWtI/7+fnprrvu0qFDh7R79+4Kf15nQ4YMkcVisT+Oi4tTUlKS25huueUWh8dvv/22ateurdTUVIef11VXXaXo6Gj7z+vsXM6ff+DAgfL3L78I+c033+jf//63hg0bpurVq1/IR3Sxfv16BQcH69Zbb3UYP3s1xQcffOAw3q1bN4WEhNgfR0VFKTIy0uHfhT/96U9asmSJpk+frs2bN+v06dNeiRW4lNFiwHm1bNlSiYmJLuOhoaE6ePCg/fGPP/4oY4y9jeDsbDm3rKxMycnJ+uGHH/TYY48pISFBwcHBKisrU8eOHVVSUlLh2MLCwhweBwYGljt+8uRJ+9iQIUP0wQcf6LHHHtM111yjWrVqyWKxqHfv3m5jiI6OdjtWXhn6yJEjMsbYy+b/KzY2VpJ+Vxn7XDF98cUXDmM1atRQrVq1HMZ+/PFHHT161P7dODu7HuRsfM7v5e/vr/Dw8HLjO7uW4ez6Cm84fPiwoqOjHRIjSYqMjJS/v7/L9+kuRqvV6vAzfuWVVzR9+nQtXLhQjz32mGrWrKn+/fvrySefdPsdA38EJAjwmoiICFksFn300Udu++dnx3bs2KEvvvhCS5YsUVpamv35b7/99qLFWlRUpLfffltTpkzRI488Yh+32Wz65Zdf3L6moKDA7ViTJk3O+T516tRRtWrVlJ+f7/LcDz/8IEkuax08ca6YnH8pOv8yPfu+4eHhWrNmjdu5z/7VfXaugoICh2rNmTNnzpvcXHHFFZKkQ4cOlXueJ8LDw/XJJ5/IGOPwuQoLC3XmzJkL+j4jIiI0d+5czZ07VwcOHNDq1av1yCOPqLCw8JzfD3C5o8UAr+nTp4+MMfr++++VmJjociQkJEj67y8r5yTi+eefd5nz7DmeVBUqwmKxyBjjEsPChQtVWlrq9jUvvfSSw+Pc3Fzt37+/3E18goOD1aFDB73++usOn6GsrEwrVqxQvXr11KxZswv+HC+//LLDYtH9+/crNze3QhsL9enTR4cPH1Zpaanbn1fz5s0lyT6X8+d/9dVX3S5e/V/NmjVT48aN9eKLL7pcYfC/PPk59+jRQ8ePH3fZRGrZsmX253+PBg0aaMyYMerVq5c+++yz3zUXcCmjggCvufbaa3X//ffrnnvu0ZYtW3T99dcrODhY+fn5ysnJUUJCgv785z+rRYsWaty4sR555BEZYxQWFqa33npL2dnZLnOeTSqeeeYZpaWlKSAgQM2bN3foKV+IWrVq6frrr9dTTz2liIgINWzYUJs2bdKiRYvOeUXCli1bdN999+m2227TwYMHNXnyZNWtW1ejRo0q970yMzPVq1cvdevWTePHj1dgYKDmz5+vHTt26OWXX3b7131FFRYWqn///ho+fLiKioo0ZcoUVa9eXRkZGed97eDBg/XSSy+pd+/eeuCBB/SnP/1JAQEBOnTokDZs2KC+ffuqf//+atmype68807NnTtXAQEB6tmzp3bs2KG//e1vLm0Ld5577jmlpqaqY8eOevDBB9WgQQMdOHBA77//vj3p8OTnfPfdd+u5555TWlqa9u3bp4SEBOXk5GjmzJnq3bu3evbs6dF3WFRUpG7dumnIkCFq0aKFQkJClJeXpzVr1mjAgAEezQVcVny4QBJV3NnV+3l5eW6fv+mmmxyuYjjrxRdfNB06dDDBwcEmKCjING7c2Nx9991my5Yt9nO++uor06tXLxMSEmLq1KljbrvtNnPgwAEjyUyZMsVhvoyMDBMbG2uqVavmsEI+Li7O3HTTTS7vL8mMHj3aYczdFQKHDh0yt9xyi6lTp44JCQkxN954o9mxY4eJi4tzWJl/9ntYu3atueuuu0zt2rVNUFCQ6d27t9mzZ895vsXffPTRR6Z79+7276Rjx47mrbfeOm+M53L2aoHly5ebv/zlL+aKK64wVqvVXHfddQ7fszG/XcUQHBzsdp7Tp0+bv/3tb6Zt27amevXqpmbNmqZFixZmxIgRDp/NZrOZhx56yERGRprq1aubjh07mo8//tjlu3J3FYMxv13hkpKSYkJDQ43VajWNGzd2uSriXD9n56sYjDHm8OHDZuTIkSYmJsb4+/ubuLg4k5GRYU6ePOlwnrt/F4wxDnGfPHnSjBw50rRp08bUqlXLBAUFmebNm5spU6Y4XAkD/NFYjHFzMTsAuyVLluiee+5RXl6e28WavrBx40Z169ZN//znP11W8wOAN7AGAQAAuCBBAAAALmgxAAAAF1QQAACACxIEAADgggQBAAC4IEEAAAAuqsxOiv6Bdc9/EgDgoji28s++DqFcQbc+Wqnzn/75O6/NFRBxpdfmupiqTIIAAECVUeb+nix/JLQYAACACyoIAAA4M2W+jsDnSBAAAHBWRoJAiwEAACfGlHnt8MSCBQvUpk0b1apVS7Vq1VKnTp303nvv2Z8fOnSoLBaLw9GxY0eHOWw2m8aOHauIiAgFBwfr5ptv1qFDhzz+DkgQAACoIurVq6cnnnhCW7Zs0ZYtW9S9e3f17dtXO3futJ9z4403Kj8/3368++67DnOkp6dr1apVysrKUk5Ojo4fP64+ffqotNSzhZe0GAAAcOajFkNqaqrD4xkzZmjBggXavHmzWrduLUmyWq2Kjo52+/qioiItWrRIy5cvV8+ePSVJK1asUP369bVu3TrdcMMNFY6FCgIAAM5MmdcOm82m4uJih8Nms503hNLSUmVlZenEiRPq1KmTfXzjxo2KjIxUs2bNNHz4cBUWFtqf27p1q06fPq3k5GT7WGxsrOLj45Wbm+vRV0CCAABAJcrMzFRoaKjDkZmZec7zt2/frpo1a8pqtWrkyJFatWqVWrVqJUlKSUnRSy+9pPXr1+vpp59WXl6eunfvbk84CgoKFBgYqDp16jjMGRUVpYKCAo/ipsUAAIAzL26UlJGRoXHjxjmMWa3Wc57fvHlzbdu2TUePHtVrr72mtLQ0bdq0Sa1atdKgQYPs58XHxysxMVFxcXF65513NGDAgHPOaYyRxWLxKG4SBAAAnHlxHwSr1VpuQuAsMDBQTZo0kSQlJiYqLy9PzzzzjJ5//nmXc2NiYhQXF6c9e/ZIkqKjo3Xq1CkdOXLEoYpQWFiopKQkj+KmxQAAQBVmjDnnmoXDhw/r4MGDiomJkSS1b99eAQEBys7Otp+Tn5+vHTt2eJwgUEEAAMCZj65imDRpklJSUlS/fn0dO3ZMWVlZ2rhxo9asWaPjx49r6tSpuuWWWxQTE6N9+/Zp0qRJioiIUP/+/SVJoaGhGjZsmB566CGFh4crLCxM48ePV0JCgv2qhooiQQAAwImnGxx5y48//qi77rpL+fn5Cg0NVZs2bbRmzRr16tVLJSUl2r59u5YtW6ajR48qJiZG3bp10yuvvKKQkBD7HHPmzJG/v78GDhyokpIS9ejRQ0uWLJGfn59HsViMMcbbH/BCcLtnAKg6/ui3e7b9e7PX5rI27nj+k6ogjysIhw4d0oIFC5Sbm6uCggJZLBZFRUUpKSlJI0eOVP369SsjTgAALh7uxeBZgpCTk2PvjSQnJys5OVnGGBUWFuqNN97Qs88+q/fee0/XXnttufPYbDaXBRcXcgkGAACVgrs5epYgPPjgg7rvvvs0Z86ccz6fnp6uvLy8cufJzMzUtGnTHMYs1WrK4lfLk3AAAKgcXtwH4VLl0RqEoKAgbdu2Tc2bN3f7/Ndff62rr75aJSUl5c7jroJQJ7wFFQQAqCL+8GsQvt7ktbmsLbp4ba6LyaMKQkxMjHJzc8+ZIHz88cf2azHL427TCJIDAECVQYvBswRh/PjxGjlypLZu3apevXopKipKFotFBQUFys7O1sKFCzV37txKChUAgIuERYqeJQijRo1SeHi45syZo+eff95+b2k/Pz+1b99ey5Yt08CBAyslUAAAcPF4fJnjoEGDNGjQIJ0+fVo///yzJCkiIkIBAQFeDw4AAJ+gxXDhOykGBARUaL0BAACXHFoM3KwJAAC44l4MAAA4MYZ9EEgQAABwxhoEWgwAAMAVFQQAAJyxSJEEAQAAF7QYSBAAAHDBzZpYgwAAAFxRQQAAwBktBhIEAABcsEiRFgMAAHBFBQEAAGe0GEgQAABwQYuBFgMAAHBFBQEAAGdUEEgQAABwxt0caTEAAAA3qCAAAOCMFgMJAgAALrjMkQQBAAAXVBBYgwAAAFxRQQAAwBktBhIEAABc0GKgxQAAAFxRQQAAwBktBhIEAABc0GKgxQAAAFxRQQAAwBkVBBIEAABcsAbB+y2GgwcP6t577y33HJvNpuLiYofDGOPtUAAAwAXyeoLwyy+/aOnSpeWek5mZqdDQUIfDlB3zdigAAFyYsjLvHZcoj1sMq1evLvf577777rxzZGRkaNy4cQ5jdcJbeBoKAACVgxaD5wlCv379ZLFYym0JWCyWcuewWq2yWq0evQYAgIvGR3/5L1iwQAsWLNC+ffskSa1bt9b/+3//TykpKZIkY4ymTZumF154QUeOHFGHDh303HPPqXXr1vY5bDabxo8fr5dfflklJSXq0aOH5s+fr3r16nkUi8cthpiYGL322msqKytze3z22WeeTgkAACTVq1dPTzzxhLZs2aItW7aoe/fu6tu3r3bu3ClJevLJJzV79mzNmzdPeXl5io6OVq9evXTs2H/b9Onp6Vq1apWysrKUk5Oj48ePq0+fPiotLfUoFo8ThPbt25ebBJyvugAAQJVnyrx2uFuYb7PZ3L5tamqqevfurWbNmqlZs2aaMWOGatasqc2bN8sYo7lz52ry5MkaMGCA4uPjtXTpUv36669auXKlJKmoqEiLFi3S008/rZ49e+rqq6/WihUrtH37dq1bt86jr8DjBOHhhx9WUlLSOZ9v0qSJNmzY4Om0AABUHV5cpOhuYX5mZuZ5QygtLVVWVpZOnDihTp06ae/evSooKFBycrL9HKvVqi5duig3N1eStHXrVp0+fdrhnNjYWMXHx9vPqSiP1yBcd9115T4fHBysLl26eDotAACXJXcL853X4f2v7du3q1OnTjp58qRq1qypVatWqVWrVvZf8FFRUQ7nR0VFaf/+/ZKkgoICBQYGqk6dOi7nFBQUeBQ3GyUBAODMi4sU3S3ML0/z5s21bds2HT16VK+99prS0tK0adMm+/POi/qNMedd6F+Rc5xxLwYAAJwZ473DQ4GBgWrSpIkSExOVmZmptm3b6plnnlF0dLQkuVQCCgsL7VWF6OhonTp1SkeOHDnnORVFggAAQBVmjJHNZlOjRo0UHR2t7Oxs+3OnTp3Spk2b7GsD27dvr4CAAIdz8vPztWPHjnLXD7pDiwEAAGc+2gdh0qRJSklJUf369XXs2DFlZWVp48aNWrNmjSwWi9LT0zVz5kw1bdpUTZs21cyZM1WjRg0NGTJEkhQaGqphw4bpoYceUnh4uMLCwjR+/HglJCSoZ8+eHsVCggAAgDMfJQg//vij7rrrLuXn5ys0NFRt2rTRmjVr1KtXL0nShAkTVFJSolGjRtk3Slq7dq1CQkLsc8yZM0f+/v4aOHCgfaOkJUuWyM/Pz6NYLKaKbFrgH1jX1yEAAP7j2Mo/+zqEcgXd+milzl/y0mNemyvojr96ba6LiQoCAADOuBcDCQIAAC4u4bswegsJAgAAzqpG992nuMwRAAC4oIIAAIAzWgwkCAAAuCBBoMUAAABcUUEAAMAZlzmSIAAA4MyUcRUDLQYAAOCCCgIAAM5YpEiCAACAC9Yg0GIAAACuqCAAAOCMRYokCAAAuGANAgkCAAAuSBBYgwAAAFxRQQAAwBm3eyZBAADABS0GWgwAAMAVFQQAAJxxmSMJAgAALthJkRYDAABw5XGCUFJSopycHH311Vcuz508eVLLli077xw2m03FxcUOh2HFKACgqigz3jsuUR4lCN98841atmyp66+/XgkJCeratavy8/PtzxcVFemee+457zyZmZkKDQ11OEzZMc+jBwCgEpiyMq8dlyqPEoSJEycqISFBhYWF2r17t2rVqqVrr71WBw4c8OhNMzIyVFRU5HBYqoV4NAcAAKg8Hi1SzM3N1bp16xQREaGIiAitXr1ao0eP1nXXXacNGzYoODi4QvNYrVZZrVaHMYvF4kkoAABUnku4NeAtHiUIJSUl8vd3fMlzzz2natWqqUuXLlq5cqVXgwMAwCe4isGzBKFFixbasmWLWrZs6TD+7LPPyhijm2++2avBAQDgE1QQPFuD0L9/f7388stun5s3b55uv/12rkYAAOAyYDFV5De6f2BdX4cAAPiPYyv/7OsQyhV066OVOv+Jqbd7ba7gqe7/sK7q2EkRAABntBjYSREAALiiggAAgDOuYiBBAADABS0GWgwAAMAVFQQAAJxcyvdQ8BYSBAAAnNFioMUAAABcUUEAAMAZFQQqCAAAuDBl3js8kJmZqWuuuUYhISGKjIxUv379tHv3bodzhg4dKovF4nB07NjR4RybzaaxY8cqIiJCwcHBuvnmm3Xo0CGPYiFBAADAWZnx3uGBTZs2afTo0dq8ebOys7N15swZJScn68SJEw7n3XjjjcrPz7cf7777rsPz6enpWrVqlbKyspSTk6Pjx4+rT58+Ki0trXAstBgAAKgi1qxZ4/B48eLFioyM1NatW3X99dfbx61Wq6Kjo93OUVRUpEWLFmn58uXq2bOnJGnFihWqX7++1q1bpxtuuKFCsZAgAABcnMn5xNchlO/Wyp3eeHENgs1mk81mcxizWq2yWq3nfW1RUZEkKSwszGF848aNioyMVO3atdWlSxfNmDFDkZGRkqStW7fq9OnTSk5Otp8fGxur+Ph45ebmVjhBoMUAAIAzL7YYMjMzFRoa6nBkZmaeNwRjjMaNG6fOnTsrPj7ePp6SkqKXXnpJ69ev19NPP628vDx1797dnoQUFBQoMDBQderUcZgvKipKBQUFFf4KqCAAAFCJMjIyNG7cOIexilQPxowZoy+//FI5OTkO44MGDbL/c3x8vBITExUXF6d33nlHAwYMOOd8xhhZLJYKx02CAACAMy/upFjRdsL/Gjt2rFavXq0PP/xQ9erVK/fcmJgYxcXFac+ePZKk6OhonTp1SkeOHHGoIhQWFiopKanCMdBiAADAmY+uYjDGaMyYMXr99de1fv16NWrU6LyvOXz4sA4ePKiYmBhJUvv27RUQEKDs7Gz7Ofn5+dqxY4dHCQIVBAAAqojRo0dr5cqVevPNNxUSEmJfMxAaGqqgoCAdP35cU6dO1S233KKYmBjt27dPkyZNUkREhPr3728/d9iwYXrooYcUHh6usLAwjR8/XgkJCfarGiqCBAEAAGc+2klxwYIFkqSuXbs6jC9evFhDhw6Vn5+ftm/frmXLluno0aOKiYlRt27d9MorrygkJMR+/pw5c+Tv76+BAweqpKREPXr00JIlS+Tn51fhWCzGmCqxn6R/YF1fhwAA+I8jo9r5OoRyhcx9q1LnLx5RsUsBK6LW8+97ba6LiTUIAADABS0GAACccbMmEgQAAFyQIJAgAADgzJtbLV+qWIMAAABcUEEAAMAZFQQSBAAAXHhvp+VLFi0GAADgggoCAABOWKR4AQnCrl27tHnzZnXq1EktWrTQ119/rWeeeUY2m0133nmnunfvft45bDab/b7VZ3l6G0oAACoNCYJnLYY1a9boqquu0vjx43X11VdrzZo1uv766/Xtt9/qwIEDuuGGG7R+/frzzpOZmanQ0FCHw5Qdu+APAQAAvMujBOHxxx/Xww8/rMOHD2vx4sUaMmSIhg8fruzsbK1bt04TJkzQE088cd55MjIyVFRU5HBYqoWc93UAAFwUZV48LlEeJQg7d+7U0KFDJUkDBw7UsWPHdMstt9ifv/322/Xll1+edx6r1apatWo5HLQXAABVhSkzXjsuVRd8FUO1atVUvXp11a5d2z4WEhKioqIib8QFAAB8yKMEoWHDhvr222/tjz/++GM1aNDA/vjgwYOKiYnxXnQAAPgCLQbPrmL485//rNLSUvvj+Ph4h+ffe++9Cl3FAABAVXYptwa8xaMEYeTIkeU+P2PGjN8VDAAAVcIl/Je/t7CTIgAAcMFOigAAODFUEEgQAABwQYJAiwEAALiiggAAgBNaDCQIAAC4IkGgxQAAAFxRQQAAwAktBhIEAABckCCQIAAA4IIEgTUIAADADSoIAAA4MxZfR+BzJAgAADihxUCLAQAAuEEFAQAAJ6aMFgMJAgAATmgx0GIAAABuUEEAAMCJ4SoGEgQAAJzRYqDFAAAA3KCCAACAE65iIEEAAMCFMb6OwPdIEAAAcEIFgTUIAADADRIEAACcmDKL1w5PZGZm6pprrlFISIgiIyPVr18/7d692zE2YzR16lTFxsYqKChIXbt21c6dOx3OsdlsGjt2rCIiIhQcHKybb75Zhw4d8igWEgQAAJwY473DE5s2bdLo0aO1efNmZWdn68yZM0pOTtaJEyfs5zz55JOaPXu25s2bp7y8PEVHR6tXr146duyY/Zz09HStWrVKWVlZysnJ0fHjx9WnTx+VlpZWOBaLMVVjKYZ/YF1fhwAA+I8jo9r5OoRyhcx9q1Ln39u2l9fmiv30bdlsNocxq9Uqq9V63tf+9NNPioyM1KZNm3T99dfLGKPY2Filp6dr4sSJkn6rFkRFRWnWrFkaMWKEioqKdMUVV2j58uUaNGiQJOmHH35Q/fr19e677+qGG26oUNxeqSBUkRwDAACv8GaLITMzU6GhoQ5HZmZmheIoKiqSJIWFhUmS9u7dq4KCAiUnJ9vPsVqt6tKli3JzcyVJW7du1enTpx3OiY2NVXx8vP2civDKVQxWq1VffPGFWrZs6Y3pAADwKW9utZyRkaFx48Y5jFWkemCM0bhx49S5c2fFx8dLkgoKCiRJUVFRDudGRUVp//799nMCAwNVp04dl3POvr4iPEoQnD/gWaWlpXriiScUHh4uSZo9e3a589hsNpdyizFGFguXlQAALi8VbSc4GzNmjL788kvl5OS4POf8+7Iiv0M9/T3rUYIwd+5ctW3bVrVr13Z50127dik4OLhCb56Zmalp06Y5jFmq1ZTFr5Yn4QAAUCl8fS+GsWPHavXq1frwww9Vr149+3h0dLSk36oEMTEx9vHCwkJ7VSE6OlqnTp3SkSNHHKoIhYWFSkpKqnAMHq1BmDFjhoqKivTYY49pw4YN9sPPz09LlizRhg0btH79+vPOk5GRoaKiIofDUi3Ek1AAAKg0ZcbitcMTxhiNGTNGr7/+utavX69GjRo5PN+oUSNFR0crOzvbPnbq1Clt2rTJ/su/ffv2CggIcDgnPz9fO3bs8ChB8KiCkJGRoZ49e+rOO+9UamqqMjMzFRAQ4MkUktyXW2gvAAD+6EaPHq2VK1fqzTffVEhIiH3NQGhoqIKCgmSxWJSenq6ZM2eqadOmatq0qWbOnKkaNWpoyJAh9nOHDRumhx56SOHh4QoLC9P48eOVkJCgnj17VjgWjxcpXnPNNdq6datGjx6txMRErVixgl/uAIDLijcXKXpiwYIFkqSuXbs6jC9evFhDhw6VJE2YMEElJSUaNWqUjhw5og4dOmjt2rUKCflvJX7OnDny9/fXwIEDVVJSoh49emjJkiXy8/OrcCy/ax+ErKwspaen66efftL27dvVqlWrC52KfRAAoAr5o++D8HWz3l6bq8U373ptrovpd13mOHjwYHXu3Flbt25VXFyct2ICAMCn2N7HC/sg1KtXz2GFJQAAuPRxu2cAAJxwu2cSBAAAXHh6eeLliLs5AgAAF1QQAABw4qvLHKsSEgQAAJxwFQMtBgAA4AYVBAAAnLBIkQQBAAAXrEGgxQAAANygggAAgBMWKZIgAADggjUIJAgAADd++sDm6xDKFXL+U34X1iCwBgEAALhBBQEAACe0GEgQAABwwRpFWgwAAMANKggAADihxUCCAACAC65ioMUAAADcoIIAAICTMl8HUAWQIAAA4MSIFgMtBgAA4IIKAgAATsrYCIEEAQAAZ2W0GEgQAABwxhoE1iAAAAA3qCAAAOCEyxxJEAAAcEGLgRYDAABw43dVEI4cOaKlS5dqz549iomJUVpamurXr3/e19lsNtlsNocxY4wsFjI2AIDv0WLwsIIQGxurw4cPS5L27t2rVq1aadasWdqzZ4+ef/55JSQk6Ouvvz7vPJmZmQoNDXU4TNmxC/sEAAB4WZkXj0uVxRhT4e0gqlWrpoKCAkVGRur2229XQUGB3nnnHdWoUUM2m0233nqrqlevrn/+85/lzuOuglAnvAUVBACoIr5p3trXIZTryu1rK3X+d6MGe22u3j9meW2ui+mCWwyffPKJFi5cqBo1akiSrFarHn30Ud16663nfa3VapXVanUYIzkAAFQVLFK8gATh7C9ym82mqKgoh+eioqL0008/eScyAAB8pIz8wPMEoUePHvL391dxcbG++eYbtW793zLUgQMHFBER4dUAAQDAxedRgjBlyhSHx2fbC2e99dZbuu66635/VAAA+BD3YvBwkWJl8g+s6+sQAAD/8UdfpPhG9BCvzdWvYKXX5rqY2EkRAAAnl/Llid7CTooAAFQRH374oVJTUxUbGyuLxaI33njD4fmhQ4fKYrE4HB07dnQ4x2azaezYsYqIiFBwcLBuvvlmHTp0yONYSBAAAHBSZrF47fDEiRMn1LZtW82bN++c59x4443Kz8+3H++++67D8+np6Vq1apWysrKUk5Oj48ePq0+fPiotLfUoFloMAAA48dXivJSUFKWkpJR7jtVqVXR0tNvnioqKtGjRIi1fvlw9e/aUJK1YsUL169fXunXrdMMNN1Q4FioIAABUIpvNpuLiYofDeTdhT2zcuFGRkZFq1qyZhg8frsLCQvtzW7du1enTp5WcnGwfi42NVXx8vHJzcz16HxIEAACcePNeDO7uP5SZmXlBcaWkpOill17S+vXr9fTTTysvL0/du3e3JxwFBQUKDAxUnTp1HF4XFRWlgoICj96LFgMAAE68uZNiRkaGxo0b5zDmfLuBiho0aJD9n+Pj45WYmKi4uDi98847GjBgwDlfdyF3TCZBAACgErm7/5C3xMTEKC4uTnv27JEkRUdH69SpUzpy5IhDFaGwsFBJSUkezU2LAQAAJ2WyeO2oTIcPH9bBgwcVExMjSWrfvr0CAgKUnZ1tPyc/P187duzwOEGgggAAgBNfXcVw/Phxffvtt/bHe/fu1bZt2xQWFqawsDBNnTpVt9xyi2JiYrRv3z5NmjRJERER6t+/vyQpNDRUw4YN00MPPaTw8HCFhYVp/PjxSkhIsF/VUFEkCAAAVBFbtmxRt27d7I/Prl1IS0vTggULtH37di1btkxHjx5VTEyMunXrpldeeUUhISH218yZM0f+/v4aOHCgSkpK1KNHDy1ZskR+fn4excK9GAAALo6MaufrEMoVMvetSp1/Wd07vTbX3d+v8NpcFxMVBAAAnHAvBhIEAABcVInSuo9xFQMAAHBBBQEAACfe3CjpUkWCAACAE9Yg0GIAAABuUEEAAMAJFQQSBAAAXBjWINBiAAAArqggAADghBYDCQIAAC5IEGgxAAAAN6ggAADghK2WSRAAAHDBTookCAAAuGANAmsQAACAG1QQAABwQgXBwwrC559/rr1799ofr1ixQtdee63q16+vzp07Kysrq0Lz2Gw2FRcXOxzGsCQEAFA1GC8elyqPEoRhw4Zp3759kqSFCxfq/vvvV2JioiZPnqxrrrlGw4cP14svvnjeeTIzMxUaGupwmLJjF/QBAACA91mMB3+6BwcHa9euXWrQoIHatWunkSNH6v7777c/v3LlSs2YMUM7d+4sdx6bzSabzeYwVie8hSwWlo0CQFVwZFQ7X4dQrpC5b1Xq/E/G3em1uSbsX+G1uS4mj9YgBAUF6aefflKDBg30/fffq0OHDg7Pd+jQwaEFcS5Wq1VWq9VhjOQAAFBVsAbBwxZDSkqKFixYIEnq0qWL/u///s/h+VdffVVNmjTxXnQAAMAnPKogzJo1S9dee626dOmixMREPf3009q4caNatmyp3bt3a/PmzVq1alVlxQoAwEVxKS8u9BaPKgixsbH6/PPP1alTJ61Zs0bGGH366adau3at6tWrp3/961/q3bt3ZcUKAMBFUSbjteNS5fE+CLVr19YTTzyhJ554ojLiAQAAVQAbJQEA4IRFiiQIAAC4uHQbA95DggAAgBMqCNysCQAAuEEFAQAAJ2Xs3UeCAACAs0v58kRvocUAAABcUEEAAMAJ9QMSBAAAXHAVAy0GAADgBhUEAACcsEiRBAEA4IZ/5w6+DsGnSA9oMQAAADeoIAAA4IRFiiQIAAC4YA0CLQYAAFwYLx6e+PDDD5WamqrY2FhZLBa98cYbjnEZo6lTpyo2NlZBQUHq2rWrdu7c6XCOzWbT2LFjFRERoeDgYN188806dOiQh5GQIAAAUGWcOHFCbdu21bx589w+/+STT2r27NmaN2+e8vLyFB0drV69eunYsWP2c9LT07Vq1SplZWUpJydHx48fV58+fVRaWupRLLQYAABw4qs1CCkpKUpJSXH7nDFGc+fO1eTJkzVgwABJ0tKlSxUVFaWVK1dqxIgRKioq0qJFi7R8+XL17NlTkrRixQrVr19f69at0w033FDhWKggAADgxHjxfzabTcXFxQ6HzWbzOKa9e/eqoKBAycnJ9jGr1aouXbooNzdXkrR161adPn3a4ZzY2FjFx8fbz6koEgQAACpRZmamQkNDHY7MzEyP5ykoKJAkRUVFOYxHRUXZnysoKFBgYKDq1KlzznMqihYDAABOvNliyMjI0Lhx4xzGrFbrBc9nsVgcHhtjXMacVeQcZ1QQAABwUibjtcNqtapWrVoOx4UkCNHR0ZLkUgkoLCy0VxWio6N16tQpHTly5JznVBQJAgAAl4BGjRopOjpa2dnZ9rFTp05p06ZNSkpKkiS1b99eAQEBDufk5+drx44d9nMqihYDAABOfLVN0vHjx/Xtt9/aH+/du1fbtm1TWFiYGjRooPT0dM2cOVNNmzZV06ZNNXPmTNWoUUNDhgyRJIWGhmrYsGF66KGHFB4errCwMI0fP14JCQn2qxoqigQBAAAnvtpJccuWLerWrZv98dm1C2lpaVqyZIkmTJigkpISjRo1SkeOHFGHDh20du1ahYSE2F8zZ84c+fv7a+DAgSopKVGPHj20ZMkS+fn5eRSLxRhTJfaT9A+s6+sQAAD/cWzln30dQrmCbn20Uucf0fA2r831/L5/em2ui4kKAgAATrhZEwkCAAAuDDdrIkEAAMAZFQQPL3McO3asPvroo9/9pu62nawiSyEAAIA8TBCee+45de3aVc2aNdOsWbM83rbxLHfbTpqyY+d/IQAAF4E378VwqfJ4o6S1a9eqd+/e+tvf/qYGDRqob9++evvtt1VWVvGCTEZGhoqKihwOS7WQ878QAICLoMyLx6XK4wQhISFBc+fO1Q8//KAVK1bIZrOpX79+ql+/viZPnuywwcO5uNt20tM9ogEAQOW54K2WAwICNHDgQK1Zs0bfffedhg8frpdeeknNmzf3ZnwAAFx0ZcZ47bhUeeVeDA0aNNDUqVO1d+9erVmzxhtTAgDgM8aLx6XKowQhLi6u3K0aLRaLevXq9buDAgAAvuXRPgh79+6trDgAAKgyfHUvhqqEjZIAAHByKV+e6C1eWYMAAAAuL1QQAABwcinvX+AtJAgAADhhDQIJAgAALliDwBoEAADgBhUEAACcsAaBBAEAABfmEt4i2VtoMQAAABdUEAAAcMJVDCQIAAC4YA0CCQIAwI0zOZ/4OoTy3errAC5/JAgAADhhHwQSBAAAXLAGgasYAACAG1QQAABwwj4IJAgAALjgKgYSBAAAXLBIkTUIAADADSoIAAA44SoGEgQAAFywSJEWAwAAcIMKAgAATmgxkCAAAOCCqxhoMQAAADeoIAAA4KSMRYokCAAAOCM9oMUAAADcoIIAAIATrmK4gArCs88+q7S0NL366quSpOXLl6tVq1Zq0aKFJk2apDNnzpx3DpvNpuLiYoeDTSkAAFVFmYzXjkuVRwnCX//6V02ePFknTpzQAw88oFmzZunBBx/UHXfcobS0NC1cuFB//etfzztPZmamQkNDHQ5TduyCPwQAAN5kjPHa4YmpU6fKYrE4HNHR0Q5xTZ06VbGxsQoKClLXrl21c+dOb398SR62GJYsWaIlS5ZowIAB+uKLL9S+fXstXbpUd9xxhySpRYsWmjBhgqZNm1buPBkZGRo3bpzDWJ3wFh6GDgDA5ad169Zat26d/bGfn5/9n5988knNnj1bS5YsUbNmzTR9+nT16tVLu3fvVkhIiFfj8ChByM/PV2JioiSpbdu2qlatmq666ir78+3atdMPP/xw3nmsVqusVqvDmMVi8SQUAAAqjS9bA/7+/g5Vg7OMMZo7d64mT56sAQMGSJKWLl2qqKgorVy5UiNGjPBqHB61GKKjo/XVV19Jkvbs2aPS0lL7Y0nauXOnIiMjvRogAAAXm/Hi/9ytu7PZbOd87z179ig2NlaNGjXS4MGD9d1330mS9u7dq4KCAiUnJ9vPtVqt6tKli3Jzc73+HXiUIAwZMkR33323hg8frhtuuEETJ07U+PHj9fe//13PP/+8Ro4cqf79+3s9SAAALlXu1t1lZma6PbdDhw5atmyZ3n//ff3jH/9QQUGBkpKSdPjwYRUUFEiSoqKiHF4TFRVlf86bPGoxTJs2TUFBQdq8ebNGjBihiRMnqk2bNpowYYJ+/fVXpaamVmiRIgAAVZk3r6xzt+7Ouc1+VkpKiv2fExIS1KlTJzVu3FhLly5Vx44dJbm25I0xldKm9yhB8PPz0+TJkx3GBg8erMGDB3s1KAAAfMmbaxDcrburqODgYCUkJGjPnj3q16+fJKmgoEAxMTH2cwoLC12qCt7ATooAAFRRNptNu3btUkxMjBo1aqTo6GhlZ2fbnz916pQ2bdqkpKQkr783OykCAODEV5v3jR8/XqmpqWrQoIEKCws1ffp0FRcXKy0tTRaLRenp6Zo5c6aaNm2qpk2baubMmapRo4aGDBni9VhIEAAAcOKryxwPHTqk22+/XT///LOuuOIKdezYUZs3b1ZcXJwkacKECSopKdGoUaN05MgRdejQQWvXrvX6HgiSZDFVZI9j/8C6vg4BAPAfR0a183UI5QqZ+1alzt822nsl+y8KvH8J4sVABQEAACfmEr6HgreQIAAA4KSsahTXfYoEAQAAJ1QQuMwRAAC4QQUBAAAntBhIEAAAcEGLgRYDAABwgwoCAMBF9Uef8XUIPkWLgQQBAAAXtBhoMQAAADeoIAAA4IQWAwkCAAAuaDHQYgAAAG5QQQAAwIkxZb4OwedIEAAAcFJGi4EEAQAAZ4ZFiqxBAAAArqggAADghBYDCQIAAC5oMdBiAAAAblBBAADACTspkiAAAOCCnRRpMQAAADeoIAAA4IRFiheQIOTn52vBggXKyclRfn6+/Pz81KhRI/Xr109Dhw6Vn59fZcQJAMBFw2WOHrYYtmzZopYtW+qtt97SyZMn9c0336hdu3YKDg7W+PHjdd111+nYsWPnncdms6m4uNjhIFsDAKDq8ChBSE9P14MPPqjPP/9cubm5Wrp0qb755htlZWXpu+++U0lJiR599NHzzpOZmanQ0FCHw5SdP7EAAOBiMMZ47bhUWYwH0deoUUM7duzQlVdeKUkqKytT9erVdfDgQUVFRSk7O1tDhw7V999/X+48NptNNpvNYaxOeAtZLJYL+AgAAG8r+eEjX4dQroCIKyt1/rCQpl6b65dje7w218Xk0RqEyMhI5efn2xOEH3/8UWfOnFGtWrUkSU2bNtUvv/xy3nmsVqusVqvDGMkBAKCquJT/8vcWj1oM/fr108iRI7VmzRpt2LBBd9xxh7p06aKgoCBJ0u7du1W3bt1KCRQAAFw8HlUQpk+frvz8fKWmpqq0tFSdOnXSihUr7M9bLBZlZmZ6PUgAAC4mrmLwcA3CWSdPntSZM2dUs2ZNrwXiH0jlAQCqij/6GoRawd6bv/jEd16b62K6oI2Sqlev7u04AABAFcJOigAAOOFmTSQIAAC44GZN3KwJAAC4QQUBAAAntBhIEAAAcMFGSbQYAACAG1QQAABwwiJFKggAALjw5d0c58+fr0aNGql69epq3769PvrIN5tWkSAAAODEVwnCK6+8ovT0dE2ePFmff/65rrvuOqWkpOjAgQOV9EnP7YK2Wq4MbLUMAFXHH32r5QAv/k46fer7Cp/boUMHtWvXTgsWLLCPtWzZUv369bvo9zqiggAAgBPjxcNms6m4uNjhsNlsLu956tQpbd26VcnJyQ7jycnJys3NrZTPWS5zGTp58qSZMmWKOXnypK9DcVGVYzOG+H6PqhybMcT3e1Tl2IwhvqpuypQpLnnDlClTXM77/vvvjSTzr3/9y2F8xowZplmzZhcp2v+qMi0GbyouLlZoaKiKiopUq1YtX4fjoCrHJhHf71GVY5OI7/eoyrFJxFfV2Ww2l4qB1WqV1Wp1GPvhhx9Ut25d5ebmqlOnTvbxGTNmaPny5fr6668vSrxncZkjAACVyF0y4E5ERIT8/PxUUFDgMF5YWKioqKjKCu+cWIMAAEAVEBgYqPbt2ys7O9thPDs7W0lJSRc9HioIAABUEePGjdNdd92lxMREderUSS+88IIOHDigkSNHXvRYLssEwWq1asqUKRUq6VxsVTk2ifh+j6ocm0R8v0dVjk0ivsvJoEGDdPjwYT3++OPKz89XfHy83n33XcXFxV30WC7LRYoAAOD3YQ0CAABwQYIAAABckCAAAAAXJAgAAMAFCQIAAHBx2SUIVeU+2s4+/PBDpaamKjY2VhaLRW+88YavQ7LLzMzUNddco5CQEEVGRqpfv37avXu3r8OyW7Bggdq0aaNatWqpVq1a6tSpk9577z1fh3VOmZmZslgsSk9P93UokqSpU6fKYrE4HNHR0b4Oy+7777/XnXfeqfDwcNWoUUNXXXWVtm7d6uuwJEkNGzZ0+e4sFotGjx7t69AkSWfOnNGjjz6qRo0aKSgoSFdeeaUef/xxlZWV+To0SdKxY8eUnp6uuLg4BQUFKSkpSXl5eb4OCxV0WSUIVek+2s5OnDihtm3bat68eb4OxcWmTZs0evRobd68WdnZ2Tpz5oySk5N14sQJX4cmSapXr56eeOIJbdmyRVu2bFH37t3Vt29f7dy509ehucjLy9MLL7ygNm3a+DoUB61bt1Z+fr792L59u69DkiQdOXJE1157rQICAvTee+/pq6++0tNPP63atWv7OjRJv/08//d7O7vD3W233ebjyH4za9Ys/f3vf9e8efO0a9cuPfnkk3rqqaf07LPP+jo0SdJ9992n7OxsLV++XNu3b1dycrJ69uyp77+v+O2P4UMX/fZQlehPf/qTGTlypMNYixYtzCOPPOKjiNyTZFatWuXrMM6psLDQSDKbNm3ydSjnVKdOHbNw4UJfh+Hg2LFjpmnTpiY7O9t06dLFPPDAA74OyRjz253k2rZt6+sw3Jo4caLp3Lmzr8OosAceeMA0btzYlJWV+ToUY4wxN910k7n33nsdxgYMGGDuvPNOH0X0X7/++qvx8/Mzb7/9tsN427ZtzeTJk30UFTxx2VQQqtx9tC9hRUVFkqSwsDAfR+KqtLRUWVlZOnHihMPdzqqC0aNH66abblLPnj19HYqLPXv2KDY2Vo0aNdLgwYP13Xff+TokSdLq1auVmJio2267TZGRkbr66qv1j3/8w9dhuXXq1CmtWLFC9957rywWi6/DkSR17txZH3zwgb755htJ0hdffKGcnBz17t3bx5H91v4oLS1V9erVHcaDgoKUk5Pjo6jgictmq+Wff/5ZpaWlLne8ioqKcrkzFs7NGKNx48apc+fOio+P93U4dtu3b1enTp108uRJ1axZU6tWrVKrVq18HZZdVlaWPvvssyrZX+3QoYOWLVumZs2a6ccff9T06dOVlJSknTt3Kjw83Kexfffdd1qwYIHGjRunSZMm6dNPP9Vf/vIXWa1W3X333T6Nzdkbb7yho0ePaujQob4OxW7ixIkqKipSixYt5Ofnp9LSUs2YMUO33367r0NTSEiIOnXqpL/+9a9q2bKloqKi9PLLL+uTTz5R06ZNfR0eKuCySRDOcs7sjTFVJtu/FIwZM0Zffvlllcvwmzdvrm3btuno0aN67bXXlJaWpk2bNlWJJOHgwYN64IEHtHbtWpe/lqqClJQU+z8nJCSoU6dOaty4sZYuXapx48b5MDKprKxMiYmJmjlzpiTp6quv1s6dO7VgwYIqlyAsWrRIKSkpio2N9XUodq+88opWrFihlStXqnXr1tq2bZvS09MVGxurtLQ0X4en5cuX695771XdunXl5+endu3aaciQIfrss898HRoq4LJJEKrafbQvRWPHjtXq1av14Ycfql69er4Ox0FgYKCaNGkiSUpMTFReXp6eeeYZPf/88z6OTNq6dasKCwvVvn17+1hpaak+/PBDzZs3TzabTX5+fj6M0FFwcLASEhK0Z88eX4eimJgYlySvZcuWeu2113wUkXv79+/XunXr9Prrr/s6FAcPP/ywHnnkEQ0ePFjSbwng/v37lZmZWSUShMaNG2vTpk06ceKEiouLFRMTo0GDBqlRo0a+Dg0VcNmsQahq99G+lBhjNGbMGL3++utav379JfF/XmOMbDabr8OQJPXo0UPbt2/Xtm3b7EdiYqLuuOMObdu2rUolB5Jks9m0a9cuxcTE+DoUXXvttS6X1H7zzTc+uXNdeRYvXqzIyEjddNNNvg7Fwa+//qpq1Rz/M+7n51dlLnM8Kzg4WDExMTpy5Ijef/999e3b19choQIumwqCVLXuo+3s+PHj+vbbb+2P9+7dq23btiksLEwNGjTwYWS/La5buXKl3nzzTYWEhNirMKGhoQoKCvJpbJI0adIkpaSkqH79+jp27JiysrK0ceNGrVmzxtehSfqt1+q8XiM4OFjh4eFVYh3H+PHjlZqaqgYNGqiwsFDTp09XcXFxlfgL88EHH1RSUpJmzpypgQMH6tNPP9ULL7ygF154wdeh2ZWVlWnx4sVKS0uTv3/V+k9mamqqZsyYoQYNGqh169b6/PPPNXv2bN17772+Dk2S9P7778sYo+bNm+vbb7/Vww8/rObNm+uee+7xdWioCJ9eQ1EJnnvuORMXF2cCAwNNu3btqsylehs2bDCSXI60tDRfh+Y2Lklm8eLFvg7NGGPMvffea/+ZXnHFFaZHjx5m7dq1vg6rXFXpMsdBgwaZmJgYExAQYGJjY82AAQPMzp07fR2W3VtvvWXi4+ON1Wo1LVq0MC+88IKvQ3Lw/vvvG0lm9+7dvg7FRXFxsXnggQdMgwYNTPXq1c2VV15pJk+ebGw2m69DM8YY88orr5grr7zSBAYGmujoaDN69Ghz9OhRX4eFCrIYY4xvUhMAAFBVXTZrEAAAgPeQIAAAABckCAAAwAUJAgAAcEGCAAAAXJAgAAAAFyQIAADABQkCAABwQYIAAABckCAAAAAXJAgAAMDF/wemYxAP9FoGKAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf.fit(X_validation, y_validation)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred))\n",
    "plt.title(\"Heatmap of predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA \n",
    "Instead of some fancy tilenet base encoding we will try to use pca to create embeddings - maybe using the simple dimentionality reduction method we will obtain comparable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=512)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=512)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=512)\n",
    "pca.fit(X_norm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X_norm_valtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model RandomForestClassifier: 75.57±0.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model LogisticRegression: 69.56±1.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "compare_results(X_pca, y_valtest, rf, folds = 5)\n",
    "compare_results(X_pca, y_valtest, lr, folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/storage/tile2vec/models/pca.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/storage/tile2vec/models/pca.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m      4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(pca, p)\n",
      "File \u001b[0;32m~/.conda/envs/tile2vec/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/storage/tile2vec/models/pca.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/storage/tile2vec/models/pca.pkl\", \"wb\") as p:\n",
    "    pickle.dump(pca, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:128: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FastICA(n_components=512)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;FastICA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.FastICA.html\">?<span>Documentation for FastICA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>FastICA(n_components=512)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "FastICA(n_components=512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "fastica = FastICA(n_components=512)\n",
    "\n",
    "fastica.fit(X_norm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model RandomForestClassifier: 76.69±0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model LogisticRegression: 64.42±1.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natalia/.conda/envs/tile2vec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_fastica = fastica.transform(X_norm_valtest)\n",
    "\n",
    "compare_results(X_fastica, y_valtest, rf, folds = 5)\n",
    "compare_results(X_fastica, y_valtest, lr, folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/storage/tile2vec/models/fastica.pkl\", \"wb\") as p:\n",
    "    pickle.dump(fastica, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans\n",
    "\n",
    "KMeans with 10 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 10)\n",
    "\n",
    "kmeans.fit(X_norm_train, y_train)\n",
    "\n",
    "X_kmeans = kmeans.transform(X_norm_valtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/storage/tile2vec/models/kmeans.pkl\", \"wb\") as p:\n",
    "    pickle.dump(kmeans, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model RandomForestClassifier: 75.15±0.82%\n",
      "Averaged accuracy for model LogisticRegression: 75.19±0.68%\n"
     ]
    }
   ],
   "source": [
    "compare_results(X_kmeans, y_valtest, rf, folds = 5)\n",
    "compare_results(X_kmeans, y_valtest, lr, folds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model RandomForestClassifier: 79.71±1.05%\n",
      "Averaged accuracy for model LogisticRegression: 79.72±1.42%\n"
     ]
    }
   ],
   "source": [
    "compare_results(X_norm_valtest, y_valtest, rf, folds = 5)\n",
    "compare_results(X_norm_valtest, y_valtest, lr, folds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.resnet import ResNet18\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "og_tilenet = ResNet18()\n",
    "if cuda: \n",
    "    og_tilenet.cuda()\n",
    "    \n",
    "\n",
    "checkpoint = torch.load(\"models/naip_trained.ckpt\")\n",
    "og_tilenet.load_state_dict(checkpoint)\n",
    "og_tilenet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:59<00:00, 92.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 5519 tiles: 59.936s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [00:29<00:00, 92.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 2759 tiles: 29.718s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_validation, y_validation = create_embeddings_tile2vec(og_tilenet, '/storage/EuroSATallBands/validation.csv', '/storage/tile2vec/tif/val', bands=4)\n",
    "X_test, y_test = create_embeddings_tile2vec(og_tilenet, '/storage/EuroSATallBands/test.csv', '/storage/tile2vec/tif/test', bands=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model RandomForestClassifier: 45.80±1.50%\n",
      "Averaged accuracy for model LogisticRegression: 45.12±1.61%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.concatenate((X_validation, X_test), axis=0)\n",
    "y = np.concatenate((y_validation, y_test), axis=0)\n",
    "\n",
    "compare_results(X, y, rf, folds = 5)\n",
    "compare_results(X, y, lr, folds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile size 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/tile2vec/models/TileNet_tile_40.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:33<00:00, 162.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 5519 tiles: 33.877s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [00:18<00:00, 150.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 2759 tiles: 18.343s\n",
      "Averaged accuracy for model RandomForestClassifier: 52.34±4.33%\n",
      "Averaged accuracy for model LogisticRegression: 51.60±4.23%\n"
     ]
    }
   ],
   "source": [
    "custom_clipping = load_model(\"TileNet_tile_40.ckpt\")\n",
    "X_validation, y_validation = create_embeddings_tile2vec(custom_clipping, '/storage/EuroSATallBands/validation.csv', '/storage/tile2vec/tif/val', \"landsat\")\n",
    "X_test, y_test = create_embeddings_tile2vec(custom_clipping, '/storage/EuroSATallBands/test.csv', '/storage/tile2vec/tif/test')\n",
    "\n",
    "X = np.concatenate((X_validation, X_test), axis=0)\n",
    "y = np.concatenate((y_validation, y_test), axis=0)\n",
    "\n",
    "compare_results(X, y, rf, folds = 5)\n",
    "compare_results(X, y, lr, folds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tile size 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/tile2vec/models/TileNet_tile_30.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:22<00:00, 248.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 5519 tiles: 22.182s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [00:12<00:00, 217.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 2759 tiles: 12.712s\n",
      "Averaged accuracy for model RandomForestClassifier: 53.66±1.17%\n",
      "Averaged accuracy for model LogisticRegression: 53.44±1.09%\n"
     ]
    }
   ],
   "source": [
    "custom_clipping = load_model(\"TileNet_tile_30.ckpt\")\n",
    "X_validation, y_validation = create_embeddings_tile2vec(custom_clipping, '/storage/EuroSATallBands/validation.csv', '/storage/tile2vec/tif/val', \"landsat\")\n",
    "X_test, y_test = create_embeddings_tile2vec(custom_clipping, '/storage/EuroSATallBands/test.csv', '/storage/tile2vec/tif/test')\n",
    "\n",
    "X = np.concatenate((X_validation, X_test), axis=0)\n",
    "y = np.concatenate((y_validation, y_test), axis=0)\n",
    "\n",
    "compare_results(X, y, rf, folds = 5)\n",
    "compare_results(X, y, lr, folds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tile size 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/tile2vec/models/TileNet_tile_60.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:17<00:00, 308.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 5519 tiles: 17.901s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [00:10<00:00, 256.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 2759 tiles: 10.757s\n",
      "Averaged accuracy for model RandomForestClassifier: 56.73±0.90%\n",
      "Averaged accuracy for model LogisticRegression: 56.43±0.97%\n"
     ]
    }
   ],
   "source": [
    "custom_clipping = load_model(\"TileNet_tile_60.ckpt\")\n",
    "X_validation, y_validation = create_embeddings_tile2vec(custom_clipping, '/storage/EuroSATallBands/validation.csv', '/storage/tile2vec/tif/val', \"landsat\")\n",
    "X_test, y_test = create_embeddings_tile2vec(custom_clipping, '/storage/EuroSATallBands/test.csv', '/storage/tile2vec/tif/test')\n",
    "\n",
    "X = np.concatenate((X_validation, X_test), axis=0)\n",
    "y = np.concatenate((y_validation, y_test), axis=0)\n",
    "\n",
    "compare_results(X, y, rf, folds = 5)\n",
    "compare_results(X, y, lr, folds = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
