{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the tiles using pretrained tile2vec\n",
    "In this notebook we are going to measure the performance of classifier on EuroSATallbands dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from time import time\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.tilenet import make_tilenet\n",
    "from src.resnet import ResNet18\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PermanentCrop/PermanentCrop_2401.tif</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PermanentCrop/PermanentCrop_1006.tif</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_1025...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SeaLake/SeaLake_1439.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>River/River_1052.tif</td>\n",
       "      <td>8</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_2292...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19313</th>\n",
       "      <td>AnnualCrop/AnnualCrop_1226.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19314</th>\n",
       "      <td>SeaLake/SeaLake_2010.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>SeaLake/SeaLake_2291.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>River/River_1323.tif</td>\n",
       "      <td>8</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19317 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Filename  Label  \\\n",
       "0                   PermanentCrop/PermanentCrop_2401.tif      6   \n",
       "1                   PermanentCrop/PermanentCrop_1006.tif      6   \n",
       "2      HerbaceousVegetation/HerbaceousVegetation_1025...      2   \n",
       "3                               SeaLake/SeaLake_1439.tif      9   \n",
       "4                                   River/River_1052.tif      8   \n",
       "...                                                  ...    ...   \n",
       "19312  HerbaceousVegetation/HerbaceousVegetation_2292...      2   \n",
       "19313                     AnnualCrop/AnnualCrop_1226.tif      0   \n",
       "19314                           SeaLake/SeaLake_2010.tif      9   \n",
       "19315                           SeaLake/SeaLake_2291.tif      9   \n",
       "19316                               River/River_1323.tif      8   \n",
       "\n",
       "                  ClassName  \n",
       "0             PermanentCrop  \n",
       "1             PermanentCrop  \n",
       "2      HerbaceousVegetation  \n",
       "3                   SeaLake  \n",
       "4                     River  \n",
       "...                     ...  \n",
       "19312  HerbaceousVegetation  \n",
       "19313            AnnualCrop  \n",
       "19314               SeaLake  \n",
       "19315               SeaLake  \n",
       "19316                 River  \n",
       "\n",
       "[19317 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tiles_train_path = Path(\"/storage/EuroSATallBands/train.csv\")\n",
    "train_paths = pd.read_csv(sample_tiles_train_path)\n",
    "\n",
    "base_eurosat_dir = Path(\"/storage/EuroSATallBands\")\n",
    "\n",
    "train_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['SeaLake/SeaLake_506.tif', 'AnnualCrop/AnnualCrop_2733.tif'],\n",
       "       ['Industrial/Industrial_56.tif', 'Forest/Forest_2590.tif'],\n",
       "       ['Pasture/Pasture_850.tif', 'AnnualCrop/AnnualCrop_2066.tif'],\n",
       "       ...,\n",
       "       ['Forest/Forest_261.tif', 'Forest/Forest_2860.tif'],\n",
       "       ['Pasture/Pasture_1697.tif', 'Pasture/Pasture_1637.tif'],\n",
       "       ['Residential/Residential_87.tif', 'SeaLake/Jakarta_000131.tif']],\n",
       "      dtype='<U50')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tiles\n",
    "\n",
    "def get_triplet_imgs(img_df, n_triplets=1000):\n",
    "    \"\"\"\n",
    "    Returns a numpy array of dimension (n_triplets, 2). First column is\n",
    "    the img name of anchor/neighbor tiles and second column is img name \n",
    "    of distant tiles.\n",
    "    \"\"\"\n",
    "    img_names = []\n",
    "    for filename in img_df[\"Filename\"]:\n",
    "        img_names.append(filename)\n",
    "    img_triplets = list(map(lambda _: random.choice(img_names), range(2 * n_triplets)))\n",
    "    img_triplets = np.array(img_triplets)\n",
    "    return img_triplets.reshape((-1, 2))\n",
    "\n",
    "n_triplets = 20000\n",
    "\n",
    "img_triplets = get_triplet_imgs(train_paths, n_triplets=n_triplets)\n",
    "img_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sample_tiles import extract_tile, sample_distant_same, sample_neighbor, load_img, sample_anchor, sample_distant_diff\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_triplet_tiles(tile_dir, img_dir, img_triplets, tile_size=50, neighborhood=100, \n",
    "                      val_type='uint8', bands_only=False, save=True, verbose=False):\n",
    "    if not os.path.exists(tile_dir):\n",
    "        os.makedirs(tile_dir)\n",
    "    size_even = (tile_size % 2 == 0)\n",
    "    tile_radius = tile_size // 2\n",
    "\n",
    "    n_triplets = img_triplets.shape[0]\n",
    "    unique_imgs = np.unique(img_triplets)\n",
    "    tiles = np.zeros((n_triplets, 3, 2), dtype=np.int16)\n",
    "\n",
    "    for img_name in tqdm(unique_imgs):\n",
    "        if img_name[-3:] == 'npy':\n",
    "            img = np.load(os.path.join(img_dir, img_name))\n",
    "        else:\n",
    "            img = load_img(os.path.join(img_dir, img_name), val_type=val_type, \n",
    "                       bands_only=bands_only)\n",
    "        img_padded = np.pad(img, pad_width=[(tile_radius, tile_radius),\n",
    "                                            (tile_radius, tile_radius), (0,0)],\n",
    "                            mode='reflect')\n",
    "        img_shape = img_padded.shape\n",
    "\n",
    "        for idx, row in enumerate(img_triplets):\n",
    "            if row[0] == img_name:\n",
    "                xa, ya = sample_anchor(img_shape, tile_radius)\n",
    "                xn, yn = sample_neighbor(img_shape, xa, ya, neighborhood, tile_radius)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"    Saving anchor and neighbor tile #{}\".format(idx))\n",
    "                    print(\"    Anchor tile center:{}\".format((xa, ya)))\n",
    "                    print(\"    Neighbor tile center:{}\".format((xn, yn)))\n",
    "                if save:\n",
    "                    tile_anchor = extract_tile(img_padded, xa, ya, tile_radius)\n",
    "                    tile_neighbor = extract_tile(img_padded, xn, yn, tile_radius)\n",
    "                    if size_even:\n",
    "                        tile_anchor = tile_anchor[:-1,:-1]\n",
    "                        tile_neighbor = tile_neighbor[:-1,:-1]\n",
    "                    np.save(os.path.join(tile_dir, '{}anchor.npy'.format(idx)), tile_anchor)\n",
    "                    np.save(os.path.join(tile_dir, '{}neighbor.npy'.format(idx)), tile_neighbor)\n",
    "                \n",
    "                tiles[idx,0,:] = xa - tile_radius, ya - tile_radius\n",
    "                tiles[idx,1,:] = xn - tile_radius, yn - tile_radius\n",
    "                \n",
    "                if row[1] == img_name:\n",
    "                    # distant image is same as anchor/neighbor image\n",
    "                    xd, yd = sample_distant_same(img_shape, xa, ya, neighborhood, tile_radius)\n",
    "                    if verbose:\n",
    "                        print(\"    Saving distant tile #{}\".format(idx))\n",
    "                        print(\"    Distant tile center:{}\".format((xd, yd)))\n",
    "                    if save:\n",
    "                        tile_distant = extract_tile(img_padded, xd, yd, tile_radius)\n",
    "                        if size_even:\n",
    "                            tile_distant = tile_distant[:-1,:-1]\n",
    "                        np.save(os.path.join(tile_dir, '{}distant.npy'.format(idx)), tile_distant)\n",
    "                    tiles[idx,2,:] = xd - tile_radius, yd - tile_radius\n",
    "            \n",
    "            elif row[1] == img_name: \n",
    "                # distant image is different from anchor/neighbor image\n",
    "                xd, yd = sample_distant_diff(img_shape, tile_radius)\n",
    "                if verbose:\n",
    "                        print(\"    Saving distant tile #{}\".format(idx))\n",
    "                        print(\"    Distant tile center:{}\".format((xd, yd)))\n",
    "                if save:\n",
    "                    tile_distant = extract_tile(img_padded, xd, yd, tile_radius)\n",
    "                    if size_even:\n",
    "                        tile_distant = tile_distant[:-1,:-1]\n",
    "                    np.save(os.path.join(tile_dir, '{}distant.npy'.format(idx)), tile_distant)\n",
    "                tiles[idx,2,:] = xd - tile_radius, yd - tile_radius\n",
    "            \n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16864 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 349/16864 [02:50<2:14:45,  2.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save the triplets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tile_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/storage/tile2vec/tiles\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m tiles \u001b[38;5;241m=\u001b[39m \u001b[43mget_triplet_tiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_eurosat_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_triplets\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 46\u001b[0m, in \u001b[0;36mget_triplet_tiles\u001b[0;34m(tile_dir, img_dir, img_triplets, tile_size, neighborhood, val_type, bands_only, save, verbose)\u001b[0m\n\u001b[1;32m     42\u001b[0m tiles[idx,\u001b[38;5;241m1\u001b[39m,:] \u001b[38;5;241m=\u001b[39m xn \u001b[38;5;241m-\u001b[39m tile_radius, yn \u001b[38;5;241m-\u001b[39m tile_radius\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m img_name:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# distant image is same as anchor/neighbor image\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     xd, yd \u001b[38;5;241m=\u001b[39m \u001b[43msample_distant_same\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mya\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighborhood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile_radius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Saving distant tile #\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "File \u001b[0;32m/volume/home/tymek/tile2vec/WB_projekt/code/src/sample_tiles.py:150\u001b[0m, in \u001b[0;36msample_distant_same\u001b[0;34m(img_shape, xa, ya, neighborhood, tile_radius)\u001b[0m\n\u001b[1;32m    148\u001b[0m xd, yd \u001b[38;5;241m=\u001b[39m xa, ya\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (xd \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m xa \u001b[38;5;241m-\u001b[39m neighborhood) \u001b[38;5;129;01mand\u001b[39;00m (xd \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m xa \u001b[38;5;241m+\u001b[39m neighborhood):\n\u001b[0;32m--> 150\u001b[0m     xd \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m tile_radius\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (yd \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m ya \u001b[38;5;241m-\u001b[39m neighborhood) \u001b[38;5;129;01mand\u001b[39;00m (yd \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m ya \u001b[38;5;241m+\u001b[39m neighborhood):\n\u001b[1;32m    152\u001b[0m     yd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, h) \u001b[38;5;241m+\u001b[39m tile_radius\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save the triplets\n",
    "tile_dir = \"/storage/tile2vec/tiles\"\n",
    "\n",
    "tiles = get_triplet_tiles(tile_dir, base_eurosat_dir, img_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import TileTripletsDataset, GetBands, RandomFlipAndRotate, ClipAndScale, ToFloatTensor, triplet_dataloader\n",
    "from src.tilenet import make_tilenet\n",
    "from src.training import prep_triplets, train_triplet_epoch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up model\n",
    "in_channels = 13\n",
    "z_dim = 512\n",
    "# Environment stuff\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_type = \"naip\" #images are in float - this parameter specifies that there is a need for normalization of floats\n",
    "tile_dir = '/storage/tile2vec/tiles'\n",
    "bands = 13\n",
    "augment = True\n",
    "batch_size = 50\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "n_triplets = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader set up complete.\n"
     ]
    }
   ],
   "source": [
    "dataloader = triplet_dataloader(img_type, tile_dir, bands=bands, augment=augment,\n",
    "                                batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, \n",
    "                                n_triplets=n_triplets, pairs_only=True)\n",
    "print('Dataloader set up complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = bands \n",
    "z_dim = 512 # output dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TileNet set up complete.\n"
     ]
    }
   ],
   "source": [
    "TileNet = make_tilenet(in_channels=in_channels, z_dim=z_dim)\n",
    "TileNet.train()\n",
    "if cuda: TileNet.cuda()\n",
    "print('TileNet set up complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizer = optim.Adam(TileNet.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "margin = 10\n",
    "l2 = 0.01\n",
    "print_every = 100\n",
    "save_models = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/storage/tile2vec/models'\n",
    "if not os.path.exists(model_dir): \n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fn = \"/storage/tile2vec/results_fn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.................\n",
      "Epoch 1: [100/10000 (1%)], Avg loss: 13.2556\n",
      "Epoch 1: [200/10000 (2%)], Avg loss: 10.3975\n",
      "Epoch 1: [300/10000 (3%)], Avg loss: 10.8796\n",
      "Epoch 1: [400/10000 (4%)], Avg loss: 9.4840\n",
      "Epoch 1: [500/10000 (5%)], Avg loss: 9.1382\n",
      "Epoch 1: [600/10000 (6%)], Avg loss: 8.5421\n",
      "Epoch 1: [700/10000 (7%)], Avg loss: 7.9467\n",
      "Epoch 1: [800/10000 (8%)], Avg loss: 8.2988\n",
      "Epoch 1: [900/10000 (9%)], Avg loss: 8.0421\n",
      "Epoch 1: [1000/10000 (10%)], Avg loss: 7.6982\n",
      "Epoch 1: [1100/10000 (11%)], Avg loss: 7.6270\n",
      "Epoch 1: [1200/10000 (12%)], Avg loss: 8.0049\n",
      "Epoch 1: [1300/10000 (13%)], Avg loss: 8.9993\n",
      "Epoch 1: [1400/10000 (14%)], Avg loss: 6.9339\n",
      "Epoch 1: [1500/10000 (15%)], Avg loss: 7.9396\n",
      "Epoch 1: [1600/10000 (16%)], Avg loss: 6.8229\n",
      "Epoch 1: [1700/10000 (17%)], Avg loss: 8.8813\n",
      "Epoch 1: [1800/10000 (18%)], Avg loss: 9.2595\n",
      "Epoch 1: [1900/10000 (19%)], Avg loss: 6.5781\n",
      "Epoch 1: [2000/10000 (20%)], Avg loss: 7.3226\n",
      "Epoch 1: [2100/10000 (21%)], Avg loss: 8.3341\n",
      "Epoch 1: [2200/10000 (22%)], Avg loss: 8.8427\n",
      "Epoch 1: [2300/10000 (23%)], Avg loss: 7.8804\n",
      "Epoch 1: [2400/10000 (24%)], Avg loss: 7.4267\n",
      "Epoch 1: [2500/10000 (25%)], Avg loss: 8.0366\n",
      "Epoch 1: [2600/10000 (26%)], Avg loss: 7.8687\n",
      "Epoch 1: [2700/10000 (27%)], Avg loss: 9.2593\n",
      "Epoch 1: [2800/10000 (28%)], Avg loss: 8.5375\n",
      "Epoch 1: [2900/10000 (29%)], Avg loss: 8.5509\n",
      "Epoch 1: [3000/10000 (30%)], Avg loss: 6.4296\n",
      "Epoch 1: [3100/10000 (31%)], Avg loss: 7.6198\n",
      "Epoch 1: [3200/10000 (32%)], Avg loss: 6.6266\n",
      "Epoch 1: [3300/10000 (33%)], Avg loss: 7.4704\n",
      "Epoch 1: [3400/10000 (34%)], Avg loss: 7.2098\n",
      "Epoch 1: [3500/10000 (35%)], Avg loss: 6.9632\n",
      "Epoch 1: [3600/10000 (36%)], Avg loss: 6.0877\n",
      "Epoch 1: [3700/10000 (37%)], Avg loss: 7.1923\n",
      "Epoch 1: [3800/10000 (38%)], Avg loss: 8.3140\n",
      "Epoch 1: [3900/10000 (39%)], Avg loss: 6.0600\n",
      "Epoch 1: [4000/10000 (40%)], Avg loss: 7.1510\n",
      "Epoch 1: [4100/10000 (41%)], Avg loss: 8.1600\n",
      "Epoch 1: [4200/10000 (42%)], Avg loss: 7.9151\n",
      "Epoch 1: [4300/10000 (43%)], Avg loss: 5.9682\n",
      "Epoch 1: [4400/10000 (44%)], Avg loss: 7.0386\n",
      "Epoch 1: [4500/10000 (45%)], Avg loss: 6.5097\n",
      "Epoch 1: [4600/10000 (46%)], Avg loss: 6.9488\n",
      "Epoch 1: [4700/10000 (47%)], Avg loss: 6.1473\n",
      "Epoch 1: [4800/10000 (48%)], Avg loss: 7.2674\n",
      "Epoch 1: [4900/10000 (49%)], Avg loss: 5.9128\n",
      "Epoch 1: [5000/10000 (50%)], Avg loss: 7.1593\n",
      "Epoch 1: [5100/10000 (51%)], Avg loss: 6.7956\n",
      "Epoch 1: [5200/10000 (52%)], Avg loss: 7.4373\n",
      "Epoch 1: [5300/10000 (53%)], Avg loss: 7.0826\n",
      "Epoch 1: [5400/10000 (54%)], Avg loss: 7.8679\n",
      "Epoch 1: [5500/10000 (55%)], Avg loss: 6.8539\n",
      "Epoch 1: [5600/10000 (56%)], Avg loss: 7.1504\n",
      "Epoch 1: [5700/10000 (57%)], Avg loss: 6.4377\n",
      "Epoch 1: [5800/10000 (58%)], Avg loss: 7.0403\n",
      "Epoch 1: [5900/10000 (59%)], Avg loss: 6.7473\n",
      "Epoch 1: [6000/10000 (60%)], Avg loss: 6.5367\n",
      "Epoch 1: [6100/10000 (61%)], Avg loss: 7.1998\n",
      "Epoch 1: [6200/10000 (62%)], Avg loss: 6.1538\n",
      "Epoch 1: [6300/10000 (63%)], Avg loss: 6.7756\n",
      "Epoch 1: [6400/10000 (64%)], Avg loss: 6.7170\n",
      "Epoch 1: [6500/10000 (65%)], Avg loss: 6.1030\n",
      "Epoch 1: [6600/10000 (66%)], Avg loss: 6.8295\n",
      "Epoch 1: [6700/10000 (67%)], Avg loss: 6.1654\n",
      "Epoch 1: [6800/10000 (68%)], Avg loss: 6.7835\n",
      "Epoch 1: [6900/10000 (69%)], Avg loss: 6.7614\n",
      "Epoch 1: [7000/10000 (70%)], Avg loss: 5.7045\n",
      "Epoch 1: [7100/10000 (71%)], Avg loss: 7.0098\n",
      "Epoch 1: [7200/10000 (72%)], Avg loss: 6.2678\n",
      "Epoch 1: [7300/10000 (73%)], Avg loss: 6.1811\n",
      "Epoch 1: [7400/10000 (74%)], Avg loss: 6.9133\n",
      "Epoch 1: [7500/10000 (75%)], Avg loss: 6.3810\n",
      "Epoch 1: [7600/10000 (76%)], Avg loss: 6.8615\n",
      "Epoch 1: [7700/10000 (77%)], Avg loss: 6.4428\n",
      "Epoch 1: [7800/10000 (78%)], Avg loss: 7.0255\n",
      "Epoch 1: [7900/10000 (79%)], Avg loss: 6.9499\n",
      "Epoch 1: [8000/10000 (80%)], Avg loss: 6.1325\n",
      "Epoch 1: [8100/10000 (81%)], Avg loss: 6.9860\n",
      "Epoch 1: [8200/10000 (82%)], Avg loss: 5.6350\n",
      "Epoch 1: [8300/10000 (83%)], Avg loss: 5.8610\n",
      "Epoch 1: [8400/10000 (84%)], Avg loss: 5.9634\n",
      "Epoch 1: [8500/10000 (85%)], Avg loss: 5.8012\n",
      "Epoch 1: [8600/10000 (86%)], Avg loss: 5.1520\n",
      "Epoch 1: [8700/10000 (87%)], Avg loss: 5.8286\n",
      "Epoch 1: [8800/10000 (88%)], Avg loss: 5.6415\n",
      "Epoch 1: [8900/10000 (89%)], Avg loss: 5.9915\n",
      "Epoch 1: [9000/10000 (90%)], Avg loss: 5.9064\n",
      "Epoch 1: [9100/10000 (91%)], Avg loss: 5.7839\n",
      "Epoch 1: [9200/10000 (92%)], Avg loss: 5.9526\n",
      "Epoch 1: [9300/10000 (93%)], Avg loss: 7.0735\n",
      "Epoch 1: [9400/10000 (94%)], Avg loss: 5.8499\n",
      "Epoch 1: [9500/10000 (95%)], Avg loss: 5.6352\n",
      "Epoch 1: [9600/10000 (96%)], Avg loss: 5.6327\n",
      "Epoch 1: [9700/10000 (97%)], Avg loss: 5.8935\n",
      "Epoch 1: [9800/10000 (98%)], Avg loss: 6.5026\n",
      "Epoch 1: [9900/10000 (99%)], Avg loss: 5.9240\n",
      "Epoch 1: [10000/10000 (100%)], Avg loss: 6.0060\n",
      "Finished epoch 1: 20.672s\n",
      "  Average loss: 7.1327\n",
      "  Average l_n: 4.5463\n",
      "  Average l_d: -11.6869\n",
      "  Average l_nd: -7.1405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "with open(results_fn, 'w') as file:\n",
    "\n",
    "    print('Begin training.................')\n",
    "    for epoch in range(0, epochs):\n",
    "        (avg_loss, avg_l_n, avg_l_d, avg_l_nd) = train_triplet_epoch(\n",
    "            TileNet, cuda, dataloader, optimizer, epoch+1, margin=margin, l2=l2,\n",
    "            print_every=print_every, t0=t0)\n",
    "        \n",
    "\n",
    "# Save model after last epoch\n",
    "if save_models:\n",
    "    model_fn = os.path.join(model_dir, 'TileNet_simple.ckpt')\n",
    "    torch.save(TileNet.state_dict(), model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert validation and training set to numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from src.data_utils import clip_and_scale_image\n",
    "validation_df = pd.read_csv(\"/storage/EuroSATallBands/validation.csv\")\n",
    "validation_path = Path(\"/storage/tile2vec/tif/val\")\n",
    "n_val_tiles = len(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:07<00:00, 703.59it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# this solution to iterate over examples is very suboptimal, one should use torch dataset\n",
    "for index, row in tqdm(validation_df.iterrows(), total=n_val_tiles):\n",
    "    # read the tile from provided filepath\n",
    "    \n",
    "    tile_filepath = base_eurosat_dir / row[\"Filename\"]\n",
    "    obj = gdal.Open(tile_filepath)\n",
    "    img = obj.ReadAsArray().astype(np.float32)\n",
    "    img = np.moveaxis(img, 0, -1)\n",
    "\n",
    "    tile = img[:, :, :bands] \n",
    "\n",
    "    tile = np.moveaxis(tile, -1, 0)\n",
    "    tile = np.expand_dims(tile, axis=0)\n",
    "\n",
    "    tile = clip_and_scale_image(tile, img_type=\"landsat\")\n",
    "    np.save(validation_path / f\"{index}.npy\", tile)\n",
    "\n",
    "t1 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [00:03<00:00, 792.18it/s] \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/storage/EuroSATallBands/test.csv\")\n",
    "test_path = Path(\"/storage/tile2vec/tif/test\")\n",
    "n_tiles = len(test_df)\n",
    "\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=n_tiles):\n",
    "    # read the tile from provided filepath\n",
    "    \n",
    "    tile_filepath = base_eurosat_dir / row[\"Filename\"]\n",
    "    obj = gdal.Open(tile_filepath)\n",
    "    img = obj.ReadAsArray().astype(np.float32)\n",
    "    img = np.moveaxis(img, 0, -1)\n",
    "\n",
    "    tile = img[:, :, :bands] \n",
    "\n",
    "    tile = np.moveaxis(tile, -1, 0)\n",
    "    tile = np.expand_dims(tile, axis=0)\n",
    "\n",
    "    tile = clip_and_scale_image(tile, img_type=\"landsat\")\n",
    "    np.save(test_path / f\"{index}.npy\", tile)\n",
    "\n",
    "t1 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1447, 0.1426, 0.1506, 0.1957, 0.2076, 0.3495, 0.4181, 0.3937,\n",
       "       0.0662, 0.0013, 0.4336, 0.2645, 0.444 ], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the single tile\n",
    "np.max(tile.squeeze(), axis = (1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipAndScale(object):\n",
    "    \"\"\"\n",
    "    Clips and scales bands to between [0, 1] for NAIP, RGB, and Landsat\n",
    "    satellite images. Clipping applies for Landsat only.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_type):\n",
    "        assert img_type in ['naip', 'rgb', 'landsat']\n",
    "        self.img_type = img_type\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample = clip_and_scale_image(sample, self.img_type)\n",
    "        return sample\n",
    "\n",
    "class ToFloatTensor(object):\n",
    "    \"\"\"\n",
    "    Converts numpy arrays to float Variables in Pytorch.\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        return sample\n",
    "\n",
    "def get_test_tile_dataloader(tile_dir):\n",
    "    transform_list = []\n",
    "    transform_list.append(ClipAndScale)\n",
    "    transform_list.append(ToFloatTensor)\n",
    "    \n",
    "    transform = transforms.Compose(transform_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TileNet(\n",
       "  (conv1): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from src.tilenet import make_tilenet\n",
    "model_dir = '/storage/tile2vec/models'\n",
    "\n",
    "model_fn = os.path.join(model_dir, 'TileNet_default.ckpt')\n",
    "bands = 13\n",
    "z_dim = 512\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "tilenet = make_tilenet(in_channels=bands, z_dim=z_dim)\n",
    "if cuda: \n",
    "    tilenet.cuda()\n",
    "\n",
    "checkpoint = torch.load(model_fn)\n",
    "tilenet.load_state_dict(checkpoint)\n",
    "tilenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5519 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:24<00:00, 227.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 5519 tiles: 24.216s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "validation_path = Path(\"/storage/tile2vec/tif/val\")\n",
    "validation_df = pd.read_csv(\"/storage/EuroSATallBands/validation.csv\")\n",
    "\n",
    "n_val_tiles = len(validation_df)\n",
    "\n",
    "\n",
    "X = np.zeros((n_val_tiles, z_dim))\n",
    "t0 = time()\n",
    "# this solution to iterate over examples is very suboptimal, one should use torch dataset\n",
    "for index in tqdm(range(n_val_tiles)):\n",
    "    # read the tile from provided filepath\n",
    "       \n",
    "    tile = np.load(validation_path / f\"{index}.npy\")  \n",
    "    tile = torch.from_numpy(tile).float()\n",
    "    tile = (tile)\n",
    "    if cuda: \n",
    "        tile = tile.cuda()\n",
    "    z = tilenet.encode(tile)\n",
    "    if cuda: \n",
    "        z = z.cpu()\n",
    "    z = z.data.numpy()\n",
    "    \n",
    "    X[index,:] = z\n",
    "\n",
    "t1 = time()\n",
    "print('Embedded {} tiles: {:0.3f}s'.format(n_val_tiles, t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = validation_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.4891304347826087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_pr = rf.predict(X_te)\n",
    "acc = rf.score(X_te, y_te)\n",
    "\n",
    "print(f\"Model accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "confusion_matrix(y_te, y_pr)\n",
    "\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_te, y_pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
