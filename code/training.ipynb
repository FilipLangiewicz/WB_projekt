{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the tiles using pretrained tile2vec\n",
    "In this notebook we are going to measure the performance of classifier on EuroSATallbands dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from time import time\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.tilenet import make_tilenet\n",
    "from src.resnet import ResNet18\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample tiles\n",
    "In order to train the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PermanentCrop/PermanentCrop_2401.tif</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PermanentCrop/PermanentCrop_1006.tif</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_1025...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SeaLake/SeaLake_1439.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>River/River_1052.tif</td>\n",
       "      <td>8</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_2292...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19313</th>\n",
       "      <td>AnnualCrop/AnnualCrop_1226.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19314</th>\n",
       "      <td>SeaLake/SeaLake_2010.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>SeaLake/SeaLake_2291.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>River/River_1323.tif</td>\n",
       "      <td>8</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19317 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Filename  Label  \\\n",
       "0                   PermanentCrop/PermanentCrop_2401.tif      6   \n",
       "1                   PermanentCrop/PermanentCrop_1006.tif      6   \n",
       "2      HerbaceousVegetation/HerbaceousVegetation_1025...      2   \n",
       "3                               SeaLake/SeaLake_1439.tif      9   \n",
       "4                                   River/River_1052.tif      8   \n",
       "...                                                  ...    ...   \n",
       "19312  HerbaceousVegetation/HerbaceousVegetation_2292...      2   \n",
       "19313                     AnnualCrop/AnnualCrop_1226.tif      0   \n",
       "19314                           SeaLake/SeaLake_2010.tif      9   \n",
       "19315                           SeaLake/SeaLake_2291.tif      9   \n",
       "19316                               River/River_1323.tif      8   \n",
       "\n",
       "                  ClassName  \n",
       "0             PermanentCrop  \n",
       "1             PermanentCrop  \n",
       "2      HerbaceousVegetation  \n",
       "3                   SeaLake  \n",
       "4                     River  \n",
       "...                     ...  \n",
       "19312  HerbaceousVegetation  \n",
       "19313            AnnualCrop  \n",
       "19314               SeaLake  \n",
       "19315               SeaLake  \n",
       "19316                 River  \n",
       "\n",
       "[19317 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tiles_train_path = Path(\"/storage/EuroSATallBands/train.csv\")\n",
    "train_paths = pd.read_csv(sample_tiles_train_path)\n",
    "\n",
    "base_eurosat_dir = Path(\"/storage/EuroSATallBands\")\n",
    "\n",
    "train_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['SeaLake/SeaLake_506.tif', 'AnnualCrop/AnnualCrop_2733.tif'],\n",
       "       ['Industrial/Industrial_56.tif', 'Forest/Forest_2590.tif'],\n",
       "       ['Pasture/Pasture_850.tif', 'AnnualCrop/AnnualCrop_2066.tif'],\n",
       "       ...,\n",
       "       ['Forest/Forest_261.tif', 'Forest/Forest_2860.tif'],\n",
       "       ['Pasture/Pasture_1697.tif', 'Pasture/Pasture_1637.tif'],\n",
       "       ['Residential/Residential_87.tif', 'SeaLake/Jakarta_000131.tif']],\n",
       "      dtype='<U50')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tiles\n",
    "\n",
    "def get_triplet_imgs(img_df, n_triplets=1000):\n",
    "    \"\"\"\n",
    "    Returns a numpy array of dimension (n_triplets, 2). First column is\n",
    "    the img name of anchor/neighbor tiles and second column is img name \n",
    "    of distant tiles.\n",
    "    \"\"\"\n",
    "    img_names = []\n",
    "    for filename in img_df[\"Filename\"]:\n",
    "        img_names.append(filename)\n",
    "    img_triplets = list(map(lambda _: random.choice(img_names), range(2 * n_triplets)))\n",
    "    img_triplets = np.array(img_triplets)\n",
    "    return img_triplets.reshape((-1, 2))\n",
    "\n",
    "n_triplets = 20000\n",
    "\n",
    "img_triplets = get_triplet_imgs(train_paths, n_triplets=n_triplets)\n",
    "img_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sample_tiles import extract_tile, sample_distant_same, sample_neighbor, load_img, sample_anchor, sample_distant_diff\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_triplet_tiles(tile_dir, img_dir, img_triplets, tile_size=50, neighborhood=100, \n",
    "                      val_type='uint8', bands_only=False, save=True, verbose=False):\n",
    "    if not os.path.exists(tile_dir):\n",
    "        os.makedirs(tile_dir)\n",
    "    size_even = (tile_size % 2 == 0)\n",
    "    tile_radius = tile_size // 2\n",
    "\n",
    "    n_triplets = img_triplets.shape[0]\n",
    "    unique_imgs = np.unique(img_triplets)\n",
    "    tiles = np.zeros((n_triplets, 3, 2), dtype=np.int16)\n",
    "\n",
    "    for img_name in tqdm(unique_imgs):\n",
    "        if img_name[-3:] == 'npy':\n",
    "            img = np.load(os.path.join(img_dir, img_name))\n",
    "        else:\n",
    "            img = load_img(os.path.join(img_dir, img_name), val_type=val_type, \n",
    "                       bands_only=bands_only)\n",
    "        img_padded = np.pad(img, pad_width=[(tile_radius, tile_radius),\n",
    "                                            (tile_radius, tile_radius), (0,0)],\n",
    "                            mode='reflect')\n",
    "        img_shape = img_padded.shape\n",
    "\n",
    "        for idx, row in enumerate(img_triplets):\n",
    "            if row[0] == img_name:\n",
    "                xa, ya = sample_anchor(img_shape, tile_radius)\n",
    "                xn, yn = sample_neighbor(img_shape, xa, ya, neighborhood, tile_radius)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"    Saving anchor and neighbor tile #{}\".format(idx))\n",
    "                    print(\"    Anchor tile center:{}\".format((xa, ya)))\n",
    "                    print(\"    Neighbor tile center:{}\".format((xn, yn)))\n",
    "                if save:\n",
    "                    tile_anchor = extract_tile(img_padded, xa, ya, tile_radius)\n",
    "                    tile_neighbor = extract_tile(img_padded, xn, yn, tile_radius)\n",
    "                    if size_even:\n",
    "                        tile_anchor = tile_anchor[:-1,:-1]\n",
    "                        tile_neighbor = tile_neighbor[:-1,:-1]\n",
    "                    np.save(os.path.join(tile_dir, '{}anchor.npy'.format(idx)), tile_anchor)\n",
    "                    np.save(os.path.join(tile_dir, '{}neighbor.npy'.format(idx)), tile_neighbor)\n",
    "                \n",
    "                tiles[idx,0,:] = xa - tile_radius, ya - tile_radius\n",
    "                tiles[idx,1,:] = xn - tile_radius, yn - tile_radius\n",
    "                \n",
    "                if row[1] == img_name:\n",
    "                    # distant image is same as anchor/neighbor image\n",
    "                    xd, yd = sample_distant_same(img_shape, xa, ya, neighborhood, tile_radius)\n",
    "                    if verbose:\n",
    "                        print(\"    Saving distant tile #{}\".format(idx))\n",
    "                        print(\"    Distant tile center:{}\".format((xd, yd)))\n",
    "                    if save:\n",
    "                        tile_distant = extract_tile(img_padded, xd, yd, tile_radius)\n",
    "                        if size_even:\n",
    "                            tile_distant = tile_distant[:-1,:-1]\n",
    "                        np.save(os.path.join(tile_dir, '{}distant.npy'.format(idx)), tile_distant)\n",
    "                    tiles[idx,2,:] = xd - tile_radius, yd - tile_radius\n",
    "            \n",
    "            elif row[1] == img_name: \n",
    "                # distant image is different from anchor/neighbor image\n",
    "                xd, yd = sample_distant_diff(img_shape, tile_radius)\n",
    "                if verbose:\n",
    "                        print(\"    Saving distant tile #{}\".format(idx))\n",
    "                        print(\"    Distant tile center:{}\".format((xd, yd)))\n",
    "                if save:\n",
    "                    tile_distant = extract_tile(img_padded, xd, yd, tile_radius)\n",
    "                    if size_even:\n",
    "                        tile_distant = tile_distant[:-1,:-1]\n",
    "                    np.save(os.path.join(tile_dir, '{}distant.npy'.format(idx)), tile_distant)\n",
    "                tiles[idx,2,:] = xd - tile_radius, yd - tile_radius\n",
    "            \n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16864 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 349/16864 [02:50<2:14:45,  2.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save the triplets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tile_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/storage/tile2vec/tiles\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m tiles \u001b[38;5;241m=\u001b[39m \u001b[43mget_triplet_tiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_eurosat_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_triplets\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 46\u001b[0m, in \u001b[0;36mget_triplet_tiles\u001b[0;34m(tile_dir, img_dir, img_triplets, tile_size, neighborhood, val_type, bands_only, save, verbose)\u001b[0m\n\u001b[1;32m     42\u001b[0m tiles[idx,\u001b[38;5;241m1\u001b[39m,:] \u001b[38;5;241m=\u001b[39m xn \u001b[38;5;241m-\u001b[39m tile_radius, yn \u001b[38;5;241m-\u001b[39m tile_radius\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m img_name:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# distant image is same as anchor/neighbor image\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     xd, yd \u001b[38;5;241m=\u001b[39m \u001b[43msample_distant_same\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mya\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighborhood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile_radius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Saving distant tile #\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "File \u001b[0;32m/volume/home/tymek/tile2vec/WB_projekt/code/src/sample_tiles.py:150\u001b[0m, in \u001b[0;36msample_distant_same\u001b[0;34m(img_shape, xa, ya, neighborhood, tile_radius)\u001b[0m\n\u001b[1;32m    148\u001b[0m xd, yd \u001b[38;5;241m=\u001b[39m xa, ya\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (xd \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m xa \u001b[38;5;241m-\u001b[39m neighborhood) \u001b[38;5;129;01mand\u001b[39;00m (xd \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m xa \u001b[38;5;241m+\u001b[39m neighborhood):\n\u001b[0;32m--> 150\u001b[0m     xd \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m tile_radius\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (yd \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m ya \u001b[38;5;241m-\u001b[39m neighborhood) \u001b[38;5;129;01mand\u001b[39;00m (yd \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m ya \u001b[38;5;241m+\u001b[39m neighborhood):\n\u001b[1;32m    152\u001b[0m     yd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, h) \u001b[38;5;241m+\u001b[39m tile_radius\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save the triplets\n",
    "tile_dir = \"/storage/tile2vec/tiles\"\n",
    "\n",
    "tiles = get_triplet_tiles(tile_dir, base_eurosat_dir, img_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import TileTripletsDataset, GetBands, RandomFlipAndRotate, ClipAndScale, ToFloatTensor, triplet_dataloader\n",
    "from src.tilenet import make_tilenet\n",
    "from src.training import prep_triplets, train_triplet_epoch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up model\n",
    "in_channels = 13\n",
    "z_dim = 512\n",
    "# Environment stuff\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_type = \"naip\" #images are in float - this parameter specifies that there is a need for normalization of floats\n",
    "tile_dir = '/storage/tile2vec/tiles'\n",
    "bands = 13\n",
    "augment = True\n",
    "batch_size = 50\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "n_triplets = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader set up complete.\n"
     ]
    }
   ],
   "source": [
    "dataloader = triplet_dataloader(img_type, tile_dir, bands=bands, augment=augment,\n",
    "                                batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, \n",
    "                                n_triplets=n_triplets, pairs_only=True)\n",
    "print('Dataloader set up complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = bands \n",
    "z_dim = 512 # output dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TileNet set up complete.\n"
     ]
    }
   ],
   "source": [
    "TileNet = make_tilenet(in_channels=in_channels, z_dim=z_dim)\n",
    "TileNet.train()\n",
    "if cuda: TileNet.cuda()\n",
    "print('TileNet set up complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizer = optim.Adam(TileNet.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "margin = 10\n",
    "l2 = 0.01\n",
    "print_every = 100\n",
    "save_models = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/storage/tile2vec/models'\n",
    "if not os.path.exists(model_dir): \n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fn = \"/storage/tile2vec/results_fn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.................\n",
      "Epoch 1: [100/10000 (1%)], Avg loss: 13.2556\n",
      "Epoch 1: [200/10000 (2%)], Avg loss: 10.3975\n",
      "Epoch 1: [300/10000 (3%)], Avg loss: 10.8796\n",
      "Epoch 1: [400/10000 (4%)], Avg loss: 9.4840\n",
      "Epoch 1: [500/10000 (5%)], Avg loss: 9.1382\n",
      "Epoch 1: [600/10000 (6%)], Avg loss: 8.5421\n",
      "Epoch 1: [700/10000 (7%)], Avg loss: 7.9467\n",
      "Epoch 1: [800/10000 (8%)], Avg loss: 8.2988\n",
      "Epoch 1: [900/10000 (9%)], Avg loss: 8.0421\n",
      "Epoch 1: [1000/10000 (10%)], Avg loss: 7.6982\n",
      "Epoch 1: [1100/10000 (11%)], Avg loss: 7.6270\n",
      "Epoch 1: [1200/10000 (12%)], Avg loss: 8.0049\n",
      "Epoch 1: [1300/10000 (13%)], Avg loss: 8.9993\n",
      "Epoch 1: [1400/10000 (14%)], Avg loss: 6.9339\n",
      "Epoch 1: [1500/10000 (15%)], Avg loss: 7.9396\n",
      "Epoch 1: [1600/10000 (16%)], Avg loss: 6.8229\n",
      "Epoch 1: [1700/10000 (17%)], Avg loss: 8.8813\n",
      "Epoch 1: [1800/10000 (18%)], Avg loss: 9.2595\n",
      "Epoch 1: [1900/10000 (19%)], Avg loss: 6.5781\n",
      "Epoch 1: [2000/10000 (20%)], Avg loss: 7.3226\n",
      "Epoch 1: [2100/10000 (21%)], Avg loss: 8.3341\n",
      "Epoch 1: [2200/10000 (22%)], Avg loss: 8.8427\n",
      "Epoch 1: [2300/10000 (23%)], Avg loss: 7.8804\n",
      "Epoch 1: [2400/10000 (24%)], Avg loss: 7.4267\n",
      "Epoch 1: [2500/10000 (25%)], Avg loss: 8.0366\n",
      "Epoch 1: [2600/10000 (26%)], Avg loss: 7.8687\n",
      "Epoch 1: [2700/10000 (27%)], Avg loss: 9.2593\n",
      "Epoch 1: [2800/10000 (28%)], Avg loss: 8.5375\n",
      "Epoch 1: [2900/10000 (29%)], Avg loss: 8.5509\n",
      "Epoch 1: [3000/10000 (30%)], Avg loss: 6.4296\n",
      "Epoch 1: [3100/10000 (31%)], Avg loss: 7.6198\n",
      "Epoch 1: [3200/10000 (32%)], Avg loss: 6.6266\n",
      "Epoch 1: [3300/10000 (33%)], Avg loss: 7.4704\n",
      "Epoch 1: [3400/10000 (34%)], Avg loss: 7.2098\n",
      "Epoch 1: [3500/10000 (35%)], Avg loss: 6.9632\n",
      "Epoch 1: [3600/10000 (36%)], Avg loss: 6.0877\n",
      "Epoch 1: [3700/10000 (37%)], Avg loss: 7.1923\n",
      "Epoch 1: [3800/10000 (38%)], Avg loss: 8.3140\n",
      "Epoch 1: [3900/10000 (39%)], Avg loss: 6.0600\n",
      "Epoch 1: [4000/10000 (40%)], Avg loss: 7.1510\n",
      "Epoch 1: [4100/10000 (41%)], Avg loss: 8.1600\n",
      "Epoch 1: [4200/10000 (42%)], Avg loss: 7.9151\n",
      "Epoch 1: [4300/10000 (43%)], Avg loss: 5.9682\n",
      "Epoch 1: [4400/10000 (44%)], Avg loss: 7.0386\n",
      "Epoch 1: [4500/10000 (45%)], Avg loss: 6.5097\n",
      "Epoch 1: [4600/10000 (46%)], Avg loss: 6.9488\n",
      "Epoch 1: [4700/10000 (47%)], Avg loss: 6.1473\n",
      "Epoch 1: [4800/10000 (48%)], Avg loss: 7.2674\n",
      "Epoch 1: [4900/10000 (49%)], Avg loss: 5.9128\n",
      "Epoch 1: [5000/10000 (50%)], Avg loss: 7.1593\n",
      "Epoch 1: [5100/10000 (51%)], Avg loss: 6.7956\n",
      "Epoch 1: [5200/10000 (52%)], Avg loss: 7.4373\n",
      "Epoch 1: [5300/10000 (53%)], Avg loss: 7.0826\n",
      "Epoch 1: [5400/10000 (54%)], Avg loss: 7.8679\n",
      "Epoch 1: [5500/10000 (55%)], Avg loss: 6.8539\n",
      "Epoch 1: [5600/10000 (56%)], Avg loss: 7.1504\n",
      "Epoch 1: [5700/10000 (57%)], Avg loss: 6.4377\n",
      "Epoch 1: [5800/10000 (58%)], Avg loss: 7.0403\n",
      "Epoch 1: [5900/10000 (59%)], Avg loss: 6.7473\n",
      "Epoch 1: [6000/10000 (60%)], Avg loss: 6.5367\n",
      "Epoch 1: [6100/10000 (61%)], Avg loss: 7.1998\n",
      "Epoch 1: [6200/10000 (62%)], Avg loss: 6.1538\n",
      "Epoch 1: [6300/10000 (63%)], Avg loss: 6.7756\n",
      "Epoch 1: [6400/10000 (64%)], Avg loss: 6.7170\n",
      "Epoch 1: [6500/10000 (65%)], Avg loss: 6.1030\n",
      "Epoch 1: [6600/10000 (66%)], Avg loss: 6.8295\n",
      "Epoch 1: [6700/10000 (67%)], Avg loss: 6.1654\n",
      "Epoch 1: [6800/10000 (68%)], Avg loss: 6.7835\n",
      "Epoch 1: [6900/10000 (69%)], Avg loss: 6.7614\n",
      "Epoch 1: [7000/10000 (70%)], Avg loss: 5.7045\n",
      "Epoch 1: [7100/10000 (71%)], Avg loss: 7.0098\n",
      "Epoch 1: [7200/10000 (72%)], Avg loss: 6.2678\n",
      "Epoch 1: [7300/10000 (73%)], Avg loss: 6.1811\n",
      "Epoch 1: [7400/10000 (74%)], Avg loss: 6.9133\n",
      "Epoch 1: [7500/10000 (75%)], Avg loss: 6.3810\n",
      "Epoch 1: [7600/10000 (76%)], Avg loss: 6.8615\n",
      "Epoch 1: [7700/10000 (77%)], Avg loss: 6.4428\n",
      "Epoch 1: [7800/10000 (78%)], Avg loss: 7.0255\n",
      "Epoch 1: [7900/10000 (79%)], Avg loss: 6.9499\n",
      "Epoch 1: [8000/10000 (80%)], Avg loss: 6.1325\n",
      "Epoch 1: [8100/10000 (81%)], Avg loss: 6.9860\n",
      "Epoch 1: [8200/10000 (82%)], Avg loss: 5.6350\n",
      "Epoch 1: [8300/10000 (83%)], Avg loss: 5.8610\n",
      "Epoch 1: [8400/10000 (84%)], Avg loss: 5.9634\n",
      "Epoch 1: [8500/10000 (85%)], Avg loss: 5.8012\n",
      "Epoch 1: [8600/10000 (86%)], Avg loss: 5.1520\n",
      "Epoch 1: [8700/10000 (87%)], Avg loss: 5.8286\n",
      "Epoch 1: [8800/10000 (88%)], Avg loss: 5.6415\n",
      "Epoch 1: [8900/10000 (89%)], Avg loss: 5.9915\n",
      "Epoch 1: [9000/10000 (90%)], Avg loss: 5.9064\n",
      "Epoch 1: [9100/10000 (91%)], Avg loss: 5.7839\n",
      "Epoch 1: [9200/10000 (92%)], Avg loss: 5.9526\n",
      "Epoch 1: [9300/10000 (93%)], Avg loss: 7.0735\n",
      "Epoch 1: [9400/10000 (94%)], Avg loss: 5.8499\n",
      "Epoch 1: [9500/10000 (95%)], Avg loss: 5.6352\n",
      "Epoch 1: [9600/10000 (96%)], Avg loss: 5.6327\n",
      "Epoch 1: [9700/10000 (97%)], Avg loss: 5.8935\n",
      "Epoch 1: [9800/10000 (98%)], Avg loss: 6.5026\n",
      "Epoch 1: [9900/10000 (99%)], Avg loss: 5.9240\n",
      "Epoch 1: [10000/10000 (100%)], Avg loss: 6.0060\n",
      "Finished epoch 1: 20.672s\n",
      "  Average loss: 7.1327\n",
      "  Average l_n: 4.5463\n",
      "  Average l_d: -11.6869\n",
      "  Average l_nd: -7.1405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "with open(results_fn, 'w') as file:\n",
    "\n",
    "    print('Begin training.................')\n",
    "    for epoch in range(0, epochs):\n",
    "        (avg_loss, avg_l_n, avg_l_d, avg_l_nd) = train_triplet_epoch(\n",
    "            TileNet, cuda, dataloader, optimizer, epoch+1, margin=margin, l2=l2,\n",
    "            print_every=print_every, t0=t0)\n",
    "        \n",
    "\n",
    "# Save model after last epoch\n",
    "if save_models:\n",
    "    model_fn = os.path.join(model_dir, 'TileNet_simple.ckpt')\n",
    "    torch.save(TileNet.state_dict(), model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert validation and training set to numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from src.data_utils import clip_and_scale_image\n",
    "validation_df = pd.read_csv(\"/storage/EuroSATallBands/validation.csv\")\n",
    "validation_path = Path(\"/storage/tile2vec/tif/val\")\n",
    "n_val_tiles = len(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:07<00:00, 703.59it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# this solution to iterate over examples is very suboptimal, one should use torch dataset\n",
    "for index, row in tqdm(validation_df.iterrows(), total=n_val_tiles):\n",
    "    # read the tile from provided filepath\n",
    "    \n",
    "    tile_filepath = base_eurosat_dir / row[\"Filename\"]\n",
    "    obj = gdal.Open(tile_filepath)\n",
    "    img = obj.ReadAsArray().astype(np.float32)\n",
    "    img = np.moveaxis(img, 0, -1)\n",
    "\n",
    "    tile = img[:, :, :bands] \n",
    "\n",
    "    tile = np.moveaxis(tile, -1, 0)\n",
    "    tile = np.expand_dims(tile, axis=0)\n",
    "\n",
    "    tile = clip_and_scale_image(tile, img_type=\"landsat\")\n",
    "    np.save(validation_path / f\"{index}.npy\", tile)\n",
    "\n",
    "t1 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [00:03<00:00, 792.18it/s] \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/storage/EuroSATallBands/test.csv\")\n",
    "test_path = Path(\"/storage/tile2vec/tif/test\")\n",
    "n_tiles = len(test_df)\n",
    "\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=n_tiles):\n",
    "    # read the tile from provided filepath\n",
    "    \n",
    "    tile_filepath = base_eurosat_dir / row[\"Filename\"]\n",
    "    obj = gdal.Open(tile_filepath)\n",
    "    img = obj.ReadAsArray().astype(np.float32)\n",
    "    img = np.moveaxis(img, 0, -1)\n",
    "\n",
    "    tile = img[:, :, :bands] \n",
    "\n",
    "    tile = np.moveaxis(tile, -1, 0)\n",
    "    tile = np.expand_dims(tile, axis=0)\n",
    "\n",
    "    tile = clip_and_scale_image(tile, img_type=\"landsat\")\n",
    "    np.save(test_path / f\"{index}.npy\", tile)\n",
    "\n",
    "t1 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1447, 0.1426, 0.1506, 0.1957, 0.2076, 0.3495, 0.4181, 0.3937,\n",
       "       0.0662, 0.0013, 0.4336, 0.2645, 0.444 ], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the single tile\n",
    "np.max(tile.squeeze(), axis = (1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipAndScale(object):\n",
    "    \"\"\"\n",
    "    Clips and scales bands to between [0, 1] for NAIP, RGB, and Landsat\n",
    "    satellite images. Clipping applies for Landsat only.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_type):\n",
    "        assert img_type in ['naip', 'rgb', 'landsat']\n",
    "        self.img_type = img_type\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample = clip_and_scale_image(sample, self.img_type)\n",
    "        return sample\n",
    "\n",
    "class ToFloatTensor(object):\n",
    "    \"\"\"\n",
    "    Converts numpy arrays to float Variables in Pytorch.\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        return sample\n",
    "\n",
    "def get_test_tile_dataloader(tile_dir):\n",
    "    transform_list = []\n",
    "    transform_list.append(ClipAndScale)\n",
    "    transform_list.append(ToFloatTensor)\n",
    "    \n",
    "    transform = transforms.Compose(transform_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TileNet(\n",
       "  (conv1): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from src.tilenet import make_tilenet\n",
    "model_dir = '/storage/tile2vec/models'\n",
    "\n",
    "model_fn = os.path.join(model_dir, 'TileNet_default_clipping.ckpt')\n",
    "bands = 13\n",
    "z_dim = 512\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "tilenet = make_tilenet(in_channels=bands, z_dim=z_dim)\n",
    "if cuda: \n",
    "    tilenet.cuda()\n",
    "\n",
    "checkpoint = torch.load(model_fn)\n",
    "tilenet.load_state_dict(checkpoint)\n",
    "tilenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5519 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 4078/5519 [00:15<00:04, 290.19it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "validation_path = Path(\"/storage/tile2vec/tif/val\")\n",
    "validation_df = pd.read_csv(\"/storage/EuroSATallBands/validation.csv\")\n",
    "\n",
    "n_val_tiles = len(validation_df)\n",
    "\n",
    "\n",
    "X = np.zeros((n_val_tiles, z_dim))\n",
    "t0 = time()\n",
    "# this solution to iterate over examples is very suboptimal, one should use torch dataset\n",
    "for index in tqdm(range(n_val_tiles)):\n",
    "    # read the tile from provided filepath\n",
    "       \n",
    "    tile = np.load(validation_path / f\"{index}.npy\")  \n",
    "    tile = torch.from_numpy(tile).float()\n",
    "    tile = (tile)\n",
    "    if cuda: \n",
    "        tile = tile.cuda()\n",
    "    z = tilenet.encode(tile)\n",
    "    if cuda: \n",
    "        z = z.cpu()\n",
    "    z = z.data.numpy()\n",
    "    \n",
    "    X[index,:] = z\n",
    "\n",
    "t1 = time()\n",
    "print('Embedded {} tiles: {:0.3f}s'.format(n_val_tiles, t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = validation_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.490036231884058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_pr = rf.predict(X_te)\n",
    "acc = rf.score(X_te, y_te)\n",
    "\n",
    "print(f\"Model accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4812561090423654"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_te, y_pr, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Heatmap of predictions')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "confusion_matrix(y_te, y_pr)\n",
    "\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_te, y_pr))\n",
    "plt.title(\"Heatmap of predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
