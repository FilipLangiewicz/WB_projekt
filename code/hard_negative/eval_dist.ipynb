{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from src.data_utils import clip_and_scale_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from src.tilenet import make_tilenet\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "def load_model(model_filepath, bands = 13, z_dim = 512):\n",
    "    \n",
    "    model_dir = Path('/storage/tile2vec/models')\n",
    "    model_fn = model_dir / model_filepath # specify which model weights are to be loaded\n",
    "    \n",
    "    bands = bands # number of bands in the input data - should matche the model\n",
    "    z_dim = z_dim # output dimension of the last layer of the encoder - should match the model\n",
    "\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "    tilenet = make_tilenet(in_channels=bands, z_dim=z_dim) \n",
    "    if cuda: \n",
    "        tilenet.cuda()\n",
    "        \n",
    "    print(\"Model filepath: \", model_fn)\n",
    "\n",
    "    checkpoint = torch.load(model_fn)\n",
    "    tilenet.load_state_dict(checkpoint)\n",
    "    tilenet.eval()\n",
    "    print(\"Model succesfully loaded\")\n",
    "    return tilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:02<00:00, 2119.32it/s]\n",
      "100%|██████████| 2759/2759 [00:01<00:00, 2504.98it/s]\n",
      "100%|██████████| 19317/19317 [00:11<00:00, 1727.10it/s]\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"/storage/EuroSATallBands/validation.csv\")\n",
    "n_tiles = len(val_df)\n",
    "tiles_path = Path(\"/storage/tile2vec/npy/val\")\n",
    "\n",
    "X_bare_val = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "X_norm_val = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "\n",
    "for index in tqdm(range(n_tiles)):\n",
    "    tile = np.load(tiles_path / f\"{index}.npy\")\n",
    "    X_norm_val[index] = clip_and_scale_image(tile, img_type=\"landsat\").flatten()\n",
    "    X_bare_val[index] = tile.flatten()\n",
    "    \n",
    "y_val = val_df[\"Label\"]\n",
    "\n",
    "test_df = pd.read_csv(\"/storage/EuroSATallBands/test.csv\")\n",
    "n_tiles = len(test_df)\n",
    "tiles_path = Path(\"/storage/tile2vec/npy/test\")\n",
    "\n",
    "X_bare_test = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "X_norm_test = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "\n",
    "for index in tqdm(range(n_tiles)):\n",
    "    tile = np.load(tiles_path / f\"{index}.npy\")\n",
    "    X_norm_test[index] = clip_and_scale_image(tile, img_type=\"landsat\").flatten()\n",
    "    X_bare_test[index] = tile.flatten()\n",
    "    \n",
    "y_test = test_df[\"Label\"]\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"/storage/EuroSATallBands/train.csv\")\n",
    "n_tiles = len(train_df)\n",
    "tiles_path = Path(\"/storage/tile2vec/npy/train\")\n",
    "\n",
    "X_bare_train = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "X_norm_train = np.zeros((n_tiles, 64 * 64 * 13), dtype=np.float32)\n",
    "\n",
    "for index in tqdm(range(n_tiles)):\n",
    "    tile = np.load(tiles_path / f\"{index}.npy\")\n",
    "    X_norm_train[index] =  clip_and_scale_image(tile, img_type=\"sentinel\").flatten()\n",
    "\n",
    "    X_bare_train[index] = tile.flatten()\n",
    "    \n",
    "y_train = train_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "y_train = train_df[\"Label\"]\n",
    "y_validation = val_df[\"Label\"]\n",
    "y_test = test_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X_norm_valtest = np.concatenate((X_norm_val, X_norm_test), axis=0)\n",
    "y_valtest = np.concatenate((y_validation, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to compare our model with different methods of dimentionality reduction. Therefore we create variables to evaluate performance of different methods. In the code above we create 6 matrices, two for each part of our data. Each matrix contains observations from sets. For instance, X_*_train contains images as rows, which are flattened to a row-vector. Each collum contains information about pixel on a specific position in the image.\n",
    "\n",
    "## Embeddings\n",
    "Below there is a function that creates embeddings from the provided path and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_embeddings_tile2vec(tilenet, \n",
    "                               df_filepath: str | Path, \n",
    "                               tiles_path: str | Path, \n",
    "                               img_type: str = \"sentinel\", \n",
    "                               bands: int = 13, \n",
    "                               z_dim: int = 512):\n",
    "    \"\"\"\n",
    "    function creates matrix X and y containing embeddings and labels, loads the tiles from directory `tiles_path`\n",
    "    \"\"\"\n",
    "    df_filepath = Path(df_filepath)\n",
    "    tiles_path = Path(tiles_path)\n",
    "    df = pd.read_csv(df_filepath)\n",
    "    n_tiles = len(df)    \n",
    "    \n",
    "    X = np.zeros((n_tiles, z_dim))\n",
    "    \n",
    "    t0 = time()\n",
    "    # this solution to iterate over examples is very suboptimal, one should use torch dataset\n",
    "    for index in tqdm(range(n_tiles)):\n",
    "        # read the tile from provided filepath\n",
    "        \n",
    "        tile = np.load(tiles_path / f\"{index}.npy\")  \n",
    "        tile = clip_and_scale_image(tile, img_type=img_type)[:, :bands,:, :]\n",
    "        tile = torch.from_numpy(tile).float()\n",
    "        tile = (tile)\n",
    "        if cuda: \n",
    "            tile = tile.cuda()\n",
    "        z = tilenet.encode(tile)\n",
    "        if cuda: \n",
    "            z = z.cpu()\n",
    "        z = z.data.numpy()\n",
    "        \n",
    "        X[index,:] = z\n",
    "\n",
    "    t1 = time()\n",
    "    print('Embedded {} tiles: {:0.3f}s'.format(n_tiles, t1-t0))\n",
    "    \n",
    "    y = df['Label'].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def compare_results(X, y, model, folds = 5, model_name = \"\"):\n",
    "    # simple method to evaluate performance of model using cross validation\n",
    "    if model_name == \"\":\n",
    "        model_name = model.__class__.__name__\n",
    "    \n",
    "    scores = cross_val_score(rf, X, y, cv=folds)\n",
    "    print(\"Averaged accuracy for model {}: {:.2f}±{:.2f}%\".format(model_name, scores.mean()*100, scores.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Finally we perform tests, each section contains code and results of evaluation - the results and model or method type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default model scaling\n",
    "Here we are going to check the performance of model with no band-specfic scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filepath:  /storage/tile2vec/models/TileNet_Distant_Diff.ckpt\n",
      "Model succesfully loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5519/5519 [00:19<00:00, 290.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 5519 tiles: 19.029s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2759/2759 [00:09<00:00, 306.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 2759 tiles: 9.004s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "no_clipping = load_model(\"TileNet_Distant_Diff.ckpt\")\n",
    "X_validation, y_validation = create_embeddings_tile2vec(no_clipping, '/storage/EuroSATallBands/validation.csv', '/storage/tile2vec/tif/val', \"landsat\")\n",
    "X_test, y_test = create_embeddings_tile2vec(no_clipping, '/storage/EuroSATallBands/test.csv', '/storage/tile2vec/tif/test', \"landsat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X_validation, X_test), axis=0)  \n",
    "y = np.concatenate((y_validation, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for model RandomForestClassifier: 65.92±0.71%\n"
     ]
    }
   ],
   "source": [
    "compare_results(X, y, rf, folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 900,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,  900,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,  900,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,  750,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,  750,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,  600,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  750,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,  900,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,  750,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 1078]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X, y)\n",
    "print(rf.score(X, y))\n",
    "confusion_matrix(y, rf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67270531, 0.65700483, 0.65700483, 0.65317221, 0.6652568 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_embeddings_tile2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_embeddings_tile2vec\u001b[49m(no_clipping,\n\u001b[1;32m      2\u001b[0m                                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/storage/EuroSATallBands/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/storage/tile2vec/npy/train\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlandsat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_embeddings_tile2vec' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, y_train = create_embeddings_tile2vec(no_clipping,\n",
    "                                    '/storage/EuroSATallBands/train.csv',\n",
    "                                    '/storage/tile2vec/npy/train',\n",
    "                                    \"landsat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compare_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompare_results\u001b[49m(X_train, y_train, rf, folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compare_results' is not defined"
     ]
    }
   ],
   "source": [
    "compare_results(X_train, y_train, rf, folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59842995, 0.58454106, 0.58695652, 0.58610272, 0.58670695])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59480676, 0.59057971, 0.58333333, 0.58670695, 0.58912387])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "cross_val_score(rf,X,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60662526, 0.60300207, 0.60781776, 0.61584261, 0.60859436])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2100,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0, 2100,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0, 2100,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0, 1750,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0, 1750,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0, 1400,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0, 1750,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 2100,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0, 1750,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 2517]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "print(rf.score(X_train,y_train))\n",
    "confusion_matrix(y_train,rf.predict(X_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
